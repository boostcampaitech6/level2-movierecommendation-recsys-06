{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQG9hL8-UQUP"
      },
      "source": [
        "# Multi-VAE\n",
        "\n",
        "이번 미션에서는 [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)에서 제안된 Multi-VAE 기반의 협업 필터링을 구현해보도록 하겠습니다. 다양한 Auto-Encoder 기반의 협업필터링이 제안된 이후에, 가장 강력하다고 평가받는 VAE 기반의 협업 필터링을 이해하는 시간을 갖도록 하겠습니다.\n",
        "\n",
        "- 이 미션은 다음 [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다. 바로 코드를 확인해보지 마시고, 최대한 직접 작성을 해보세요!\n",
        "- 이 미션에서 중요한 부분은 모델 부분입니다. 데이터 전처리 부분은 가볍게 훑어 보시고, 모델 부분을 집중해주세요!\n",
        "\n",
        "### 변경사항\n",
        "1. label을 확률값$\\frac{1}{\\sqrt{n}}$로 조정한 soft label 적용\n",
        "    - 이 과정에서 전처리 함수 sparse2tensor로 조정 (이게 왜 다항분포??)\n",
        "    - 각자 독립인 logistic loss도 실험 예정 -> 다항분포 해결은 이걸로 해결되는건가 싶기도 함\n",
        "    - normalize 덜 smooth하게도 고려 중\n",
        "\n",
        "\n",
        "2. tr_uid: userplays.index -> userplays.user 로 조정 (전체 데이터 셋에 등장하지도 않는 유저번호0번 같은 유령유저가 데이터셋에 포함됨)\n",
        "    - 데이터셋에 모든 interaction 0인 유저들 넘쳐났었음\n",
        "    - normalize 시 divide by 0 해결\n",
        "\n",
        "3. 내일 아침 할거\n",
        "    - userid 질문\n",
        "    - 기본 inference 구현\n",
        "    - public 제출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CfnRw7U59C"
      },
      "source": [
        "## 1. 초기 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylGzdjCI2ujg",
        "outputId": "09aaad72-83a5-4420-d27a-c5910250328e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bottleneck in /opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages (from bottleneck) (1.26.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# bottleneck은 C로 작성된 빠른 NumPy 배열 함수 모음입니다.\n",
        "!pip install bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bQj6k1mSbxaz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import argparse\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMWYLPFIjon8"
      },
      "source": [
        "## 데이터 다운로드\n",
        "이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요.\n",
        "- 데이터 URL은 변경될 수 있습니다.\n",
        "- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = '../../data/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ3W0udmbxa3",
        "outputId": "e06b80ea-6ed1-4406-e03c-e9bfe67f9946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 각종 파라미터 세팅\n",
        "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
        "\n",
        "\n",
        "parser.add_argument('--data', type=str, default=data_dir,\n",
        "                    help='Movielens dataset location')\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=1e-3,\n",
        "                    help='initial learning rate')\n",
        "parser.add_argument('--wd', type=float, default=0.00,\n",
        "                    help='weight decay coefficient')\n",
        "parser.add_argument('--batch_size', type=int, default=500,\n",
        "                    help='batch size')\n",
        "parser.add_argument('--epochs', type=int, default=20,\n",
        "                    help='upper epoch limit')\n",
        "parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
        "                    help='the total number of gradient updates for annealing')\n",
        "parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
        "                    help='largest annealing parameter')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--cuda', action='store_true',\n",
        "                    help='use CUDA')\n",
        "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
        "                    help='report interval')\n",
        "parser.add_argument('--save', type=str, default='model.pt',\n",
        "                    help='path to save the final model')\n",
        "args = parser.parse_args([])\n",
        "\n",
        "# Set the random seed manually for reproductibility.\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
        "if torch.cuda.is_available():\n",
        "    args.cuda = True\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o1fvXqFWE_G"
      },
      "source": [
        "##2. 데이터 전처리\n",
        "\n",
        "이 부분에서 진행되는 과정은 저희가 일반적으로 알고있는 MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. 전처리 과정의 다양한 옵션들을 구성하기 위해 약간 복잡하게 되었지만,\n",
        "결과적으로는, 유저들의 특정한 아이템들을 따로 분리를 해서, 그 분리된 값을 모델이 예측할 수 있냐를 확인하기 위한 전처리 과정이라고 보시면 되겠습니다.\n",
        "실제로 나오는 데이터셋을 확인하면 더욱 이해가 빠를것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cgvNoy1Ybxa6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "\n",
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "\n",
        "    return count\n",
        "\n",
        "# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상)\n",
        "# 데이터만을 추출할 때 사용하는 함수입니다.\n",
        "# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n",
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'item')\n",
        "        tp = tp[tp['item'].isin(itemcount[itemcount['size'] >= min_sc]['item'])]\n",
        "\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'user')\n",
        "        tp = tp[tp['user'].isin(usercount[usercount['size'] >= min_uc]['user'])]\n",
        "\n",
        "    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n",
        "    return tp, usercount, itemcount\n",
        "\n",
        "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n",
        "#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n",
        "#확인하기 위함입니다.\n",
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('user')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for _, group in data_grouped_by_user:\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "\n",
        "    return data_tr, data_te\n",
        "\n",
        "def numerize(tp, profile2id, show2id):\n",
        "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
        "    sid = tp['item'].apply(lambda x: show2id[x])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVFoRHrmVQsp",
        "outputId": "c96f119e-524e-4329-b89d-ed745e0eaf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load and Preprocess Movielens dataset\n",
            "원본 데이터\n",
            "            user   item        time\n",
            "0            11   4643  1230782529\n",
            "1            11    170  1230782534\n",
            "2            11    531  1230782539\n",
            "3            11    616  1230782542\n",
            "4            11   2140  1230782563\n",
            "...         ...    ...         ...\n",
            "5154466  138493  44022  1260209449\n",
            "5154467  138493   4958  1260209482\n",
            "5154468  138493  68319  1260209720\n",
            "5154469  138493  40819  1260209726\n",
            "5154470  138493  27311  1260209807\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n",
            "            user   item        time\n",
            "0            11   4643  1230782529\n",
            "1            11    170  1230782534\n",
            "2            11    531  1230782539\n",
            "3            11    616  1230782542\n",
            "4            11   2140  1230782563\n",
            "...         ...    ...         ...\n",
            "5154466  138493  44022  1260209449\n",
            "5154467  138493   4958  1260209482\n",
            "5154468  138493  68319  1260209720\n",
            "5154469  138493  40819  1260209726\n",
            "5154470  138493  27311  1260209807\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "유저별 리뷰수\n",
            "          user  size\n",
            "0          11   376\n",
            "1          14   180\n",
            "2          18    77\n",
            "3          25    91\n",
            "4          31   154\n",
            "...       ...   ...\n",
            "31355  138473    63\n",
            "31356  138475   124\n",
            "31357  138486   137\n",
            "31358  138492    68\n",
            "31359  138493   314\n",
            "\n",
            "[31360 rows x 2 columns]\n",
            "아이템별 리뷰수\n",
            "         item   size\n",
            "0          1  12217\n",
            "1          2   3364\n",
            "2          3    734\n",
            "3          4     43\n",
            "4          5    590\n",
            "...      ...    ...\n",
            "6802  118700     54\n",
            "6803  118900     60\n",
            "6804  118997     52\n",
            "6805  119141    122\n",
            "6806  119145     78\n",
            "\n",
            "[6807 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Load and Preprocess Movielens dataset\")\n",
        "# Load Data\n",
        "DATA_DIR = args.data\n",
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n",
        "print(\"원본 데이터\\n\", raw_data)\n",
        "\n",
        "# Filter Data\n",
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n",
        "#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n",
        "print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n",
        "\n",
        "print(\"유저별 리뷰수\\n\",user_activity)\n",
        "print(\"아이템별 리뷰수\\n\",item_popularity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5154471 entries, 0 to 5154470\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Dtype\n",
            "---  ------  -----\n",
            " 0   user    int64\n",
            " 1   item    int64\n",
            " 2   time    int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 118.0 MB\n"
          ]
        }
      ],
      "source": [
        "raw_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T1dTsWUrffP",
        "outputId": "6ceb7d17-d6e8-4a44-cafa-f3f84cadc6fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(BEFORE) unique_uid: 0            11\n",
            "1            14\n",
            "2            18\n",
            "3            25\n",
            "4            31\n",
            "          ...  \n",
            "31355    138473\n",
            "31356    138475\n",
            "31357    138486\n",
            "31358    138492\n",
            "31359    138493\n",
            "Name: user, Length: 31360, dtype: int64\n",
            "(AFTER) unique_uid: 6392      27968\n",
            "15438     67764\n",
            "603        2581\n",
            "18877     82969\n",
            "31197    137831\n",
            "          ...  \n",
            "30685    135379\n",
            "28589    125855\n",
            "9580      41891\n",
            "3571      15720\n",
            "3861      17029\n",
            "Name: user, Length: 31360, dtype: int64\n",
            "훈련 데이터에 사용될 사용자 수: 28360\n",
            "검증 데이터에 사용될 사용자 수: 0\n",
            "테스트 데이터에 사용될 사용자 수: 3000\n"
          ]
        }
      ],
      "source": [
        "# Shuffle User Indices\n",
        "unique_uid = user_activity.user # 아무리봐도 여기 이상한데?\n",
        "print(\"(BEFORE) unique_uid:\",unique_uid)\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]\n",
        "print(\"(AFTER) unique_uid:\",unique_uid)\n",
        "\n",
        "n_users = unique_uid.size #31360\n",
        "n_heldout_users = 3000\n",
        "\n",
        "\n",
        "# Split Train/Validation/Test User Indices\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # val 3000명\n",
        "te_users = unique_uid[(n_users - n_heldout_users):] # test 3000명\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users): (n_users - n_heldout_users)] # val 3000명\n",
        "\n",
        "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
        "print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n",
        "print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n",
        "print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'raw_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_data\u001b[39m.\u001b[39minfo()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
          ]
        }
      ],
      "source": [
        "raw_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yBsRCRqtPz6",
        "outputId": "fa16f7f7-09c9-42f3-b350-87168c60d12a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[382], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m vad_plays \u001b[39m=\u001b[39m raw_data\u001b[39m.\u001b[39mloc[raw_data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(vd_users)]\n\u001b[1;32m     22\u001b[0m vad_plays \u001b[39m=\u001b[39m vad_plays\u001b[39m.\u001b[39mloc[vad_plays[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(unique_sid)]\n\u001b[0;32m---> 23\u001b[0m vad_plays_tr, vad_plays_te \u001b[39m=\u001b[39m split_train_test_proportion(vad_plays)\n\u001b[1;32m     25\u001b[0m test_plays \u001b[39m=\u001b[39m raw_data\u001b[39m.\u001b[39mloc[raw_data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(te_users)]\n\u001b[1;32m     26\u001b[0m test_plays \u001b[39m=\u001b[39m test_plays\u001b[39m.\u001b[39mloc[test_plays[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(unique_sid)]\n",
            "Cell \u001b[0;32mIn[5], line 49\u001b[0m, in \u001b[0;36msplit_train_test_proportion\u001b[0;34m(data, test_prop)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         tr_list\u001b[39m.\u001b[39mappend(group)\n\u001b[0;32m---> 49\u001b[0m data_tr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(tr_list)\n\u001b[1;32m     50\u001b[0m data_te \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(te_list)\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m data_tr, data_te\n",
            "File \u001b[0;32m~/miniconda3/envs/movie/lib/python3.10/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
            "File \u001b[0;32m~/miniconda3/envs/movie/lib/python3.10/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
            "File \u001b[0;32m~/miniconda3/envs/movie/lib/python3.10/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "##훈련 데이터에 해당하는 아이템들\n",
        "#Train는 25360명만 사용\n",
        "train_plays = raw_data.loc[raw_data['user'].isin(tr_users)] # index 아닌 user 번호 기준 검색 -> unique_uid user 번호로 바꿔야 해!\n",
        "\n",
        "##아이템 ID\n",
        "unique_sid = pd.unique(train_plays['item'])\n",
        "\n",
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
        "\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)\n",
        "\n",
        "#Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n",
        "vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
        "\n",
        "test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n",
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
        "\n",
        "\n",
        "\n",
        "train_data = numerize(train_plays, profile2id, show2id)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
        "\n",
        "\n",
        "vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
        "\n",
        "vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
        "\n",
        "test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
        "\n",
        "test_data_te = numerize(test_plays_te, profile2id, show2id)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n",
        "\n",
        "inf_data = raw_data[['user','item']].copy()\n",
        "inf_data = numerize(inf_data, profile2id, show2id)\n",
        "inf_data.to_csv(os.path.join(pro_dir, 'inference.csv'), index=False)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkdg2OkjqVUM",
        "outputId": "28e101f0-e9ed-474b-8f3b-1fc161872ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 17)\t1.0\n",
            "  (0, 40)\t1.0\n",
            "  (0, 41)\t1.0\n",
            "  (0, 46)\t1.0\n",
            "  (0, 70)\t1.0\n",
            "  (0, 78)\t1.0\n",
            "  (0, 79)\t1.0\n",
            "  (0, 80)\t1.0\n",
            "  (0, 82)\t1.0\n",
            "  (0, 85)\t1.0\n",
            "  (0, 198)\t1.0\n",
            "  (0, 200)\t1.0\n",
            "  (0, 233)\t1.0\n",
            "  (0, 260)\t1.0\n",
            "  (0, 264)\t1.0\n",
            "  (0, 266)\t1.0\n",
            "  (0, 269)\t1.0\n",
            "  (0, 270)\t1.0\n",
            "  (0, 271)\t1.0\n",
            "  (0, 272)\t1.0\n",
            "  (0, 285)\t1.0\n",
            "  (0, 287)\t1.0\n",
            "  (0, 292)\t1.0\n",
            "  (0, 294)\t1.0\n",
            "  (0, 308)\t1.0\n",
            "  :\t:\n",
            "  (25359, 1429)\t1.0\n",
            "  (25359, 1447)\t1.0\n",
            "  (25359, 1794)\t1.0\n",
            "  (25359, 1872)\t1.0\n",
            "  (25359, 2436)\t1.0\n",
            "  (25359, 2669)\t1.0\n",
            "  (25359, 2776)\t1.0\n",
            "  (25359, 2777)\t1.0\n",
            "  (25359, 2860)\t1.0\n",
            "  (25359, 2882)\t1.0\n",
            "  (25359, 3041)\t1.0\n",
            "  (25359, 3063)\t1.0\n",
            "  (25359, 3101)\t1.0\n",
            "  (25359, 3247)\t1.0\n",
            "  (25359, 3340)\t1.0\n",
            "  (25359, 3886)\t1.0\n",
            "  (25359, 3956)\t1.0\n",
            "  (25359, 4293)\t1.0\n",
            "  (25359, 4328)\t1.0\n",
            "  (25359, 4492)\t1.0\n",
            "  (25359, 4606)\t1.0\n",
            "  (25359, 4915)\t1.0\n",
            "  (25359, 4946)\t1.0\n",
            "  (25359, 5026)\t1.0\n",
            "  (25359, 6637)\t1.0\n",
            "  (0, 17)\t1.0\n",
            "  (0, 46)\t1.0\n",
            "  (0, 79)\t1.0\n",
            "  (0, 82)\t1.0\n",
            "  (0, 116)\t1.0\n",
            "  (0, 149)\t1.0\n",
            "  (0, 159)\t1.0\n",
            "  (0, 196)\t1.0\n",
            "  (0, 198)\t1.0\n",
            "  (0, 207)\t1.0\n",
            "  (0, 209)\t1.0\n",
            "  (0, 260)\t1.0\n",
            "  (0, 266)\t1.0\n",
            "  (0, 270)\t1.0\n",
            "  (0, 289)\t1.0\n",
            "  (0, 292)\t1.0\n",
            "  (0, 358)\t1.0\n",
            "  (0, 362)\t1.0\n",
            "  (0, 366)\t1.0\n",
            "  (0, 375)\t1.0\n",
            "  (0, 591)\t1.0\n",
            "  (0, 639)\t1.0\n",
            "  (0, 645)\t1.0\n",
            "  (0, 718)\t1.0\n",
            "  (0, 774)\t1.0\n",
            "  :\t:\n",
            "  (2999, 833)\t1.0\n",
            "  (2999, 943)\t1.0\n",
            "  (2999, 946)\t1.0\n",
            "  (2999, 972)\t1.0\n",
            "  (2999, 993)\t1.0\n",
            "  (2999, 1040)\t1.0\n",
            "  (2999, 1050)\t1.0\n",
            "  (2999, 1062)\t1.0\n",
            "  (2999, 1144)\t1.0\n",
            "  (2999, 1158)\t1.0\n",
            "  (2999, 1235)\t1.0\n",
            "  (2999, 1248)\t1.0\n",
            "  (2999, 1287)\t1.0\n",
            "  (2999, 1302)\t1.0\n",
            "  (2999, 1338)\t1.0\n",
            "  (2999, 1398)\t1.0\n",
            "  (2999, 1504)\t1.0\n",
            "  (2999, 2003)\t1.0\n",
            "  (2999, 2165)\t1.0\n",
            "  (2999, 3378)\t1.0\n",
            "  (2999, 3406)\t1.0\n",
            "  (2999, 4199)\t1.0\n",
            "  (2999, 4536)\t1.0\n",
            "  (2999, 5275)\t1.0\n",
            "  (2999, 5503)\t1.0\n",
            "  (0, 210)\t1.0\n",
            "  (0, 560)\t1.0\n",
            "  (0, 685)\t1.0\n",
            "  (0, 690)\t1.0\n",
            "  (0, 711)\t1.0\n",
            "  (0, 935)\t1.0\n",
            "  (0, 1040)\t1.0\n",
            "  (0, 1154)\t1.0\n",
            "  (0, 3123)\t1.0\n",
            "  (1, 86)\t1.0\n",
            "  (1, 116)\t1.0\n",
            "  (1, 148)\t1.0\n",
            "  (1, 159)\t1.0\n",
            "  (1, 186)\t1.0\n",
            "  (1, 207)\t1.0\n",
            "  (1, 264)\t1.0\n",
            "  (1, 270)\t1.0\n",
            "  (1, 283)\t1.0\n",
            "  (1, 292)\t1.0\n",
            "  (1, 300)\t1.0\n",
            "  (1, 306)\t1.0\n",
            "  (1, 359)\t1.0\n",
            "  (1, 482)\t1.0\n",
            "  (1, 632)\t1.0\n",
            "  (1, 1526)\t1.0\n",
            "  :\t:\n",
            "  (2997, 853)\t1.0\n",
            "  (2997, 1150)\t1.0\n",
            "  (2997, 1451)\t1.0\n",
            "  (2998, 41)\t1.0\n",
            "  (2998, 82)\t1.0\n",
            "  (2998, 144)\t1.0\n",
            "  (2998, 265)\t1.0\n",
            "  (2998, 362)\t1.0\n",
            "  (2998, 566)\t1.0\n",
            "  (2998, 782)\t1.0\n",
            "  (2998, 1016)\t1.0\n",
            "  (2998, 1916)\t1.0\n",
            "  (2998, 2212)\t1.0\n",
            "  (2999, 277)\t1.0\n",
            "  (2999, 312)\t1.0\n",
            "  (2999, 462)\t1.0\n",
            "  (2999, 483)\t1.0\n",
            "  (2999, 662)\t1.0\n",
            "  (2999, 810)\t1.0\n",
            "  (2999, 952)\t1.0\n",
            "  (2999, 1015)\t1.0\n",
            "  (2999, 1369)\t1.0\n",
            "  (2999, 2175)\t1.0\n",
            "  (2999, 2188)\t1.0\n",
            "  (2999, 3380)\t1.0\n"
          ]
        }
      ],
      "source": [
        "#데이터 셋 확인\n",
        "print(train_data)\n",
        "print(vad_data_tr)\n",
        "print(vad_data_te)\n",
        "# print(test_data_tr)\n",
        "# print(test_data_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMiq9leyWWL1"
      },
      "source": [
        "##3. 데이터 로더 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "nxUADr9ibxa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataLoader(): # 존재하지도 않는 user가 sparse matrix 상에 포함됨\n",
        "    '''\n",
        "    Load Movielens dataset\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "\n",
        "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
        "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
        "\n",
        "        self.n_items = self.load_n_items()\n",
        "\n",
        "    def load_data(self, datatype='train'):\n",
        "        if datatype == 'train':\n",
        "            return self._load_train_data()\n",
        "        elif datatype == 'validation':\n",
        "            return self._load_tr_te_data(datatype)\n",
        "        elif datatype == 'test':\n",
        "            return self._load_tr_te_data(datatype)\n",
        "        elif datatype == 'inference':\n",
        "            return self._load_inf_data(datatype)\n",
        "        else:\n",
        "            raise ValueError(\"datatype should be in [train, validation, test, inference]\")\n",
        "\n",
        "    def load_n_items(self):\n",
        "        unique_sid = list()\n",
        "        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "            for line in f:\n",
        "                unique_sid.append(line.strip())\n",
        "        n_items = len(unique_sid)\n",
        "        return n_items\n",
        "\n",
        "    def _load_train_data(self):\n",
        "        path = os.path.join(self.pro_dir, 'train.csv')\n",
        "\n",
        "        tp = pd.read_csv(path)\n",
        "        n_users = tp['uid'].max() + 1\n",
        "\n",
        "        rows, cols = tp['uid'], tp['sid']\n",
        "        data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                                 (rows, cols)), dtype='float64',\n",
        "                                 shape=(n_users, self.n_items)) # uid,sid에만 1 채우고 나머지는 모두 0을 채우는 sparse interaction matrix\n",
        "        return data\n",
        "\n",
        "    def _load_tr_te_data(self, datatype='test'):\n",
        "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
        "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
        "\n",
        "        tp_tr = pd.read_csv(tr_path)\n",
        "        tp_te = pd.read_csv(te_path)\n",
        "\n",
        "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
        "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
        "        \n",
        "        return data_tr, data_te\n",
        "    \n",
        "    def _load_inf_data(self, datatype='inference'):\n",
        "        inf_path = os.path.join(self.pro_dir, 'inference.csv')\n",
        "\n",
        "        data_inf = pd.read_csv(inf_path)\n",
        "\n",
        "        n_rows = data_inf.uid.nunique()\n",
        "        n_cols = data_inf.sid.nunique()\n",
        "\n",
        "        rows = data_inf['uid']\n",
        "        cols = data_inf['sid']\n",
        "\n",
        "        data_inf = sparse.csr_matrix((np.ones_like(rows),\n",
        "                                    (rows, cols)), dtype='float64', shape=(n_rows, n_cols))\n",
        "\n",
        "        return data_inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHhwKqXWaUZ"
      },
      "source": [
        "## 4. 모델정의\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "id": "QYlGPJTYU0ii"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#이미 완성된 MultiDAE의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n",
        "class MultiDAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Container module for Multi-DAE.\n",
        "\n",
        "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
        "    See Variational Autoencoders for Collaborative Filtering\n",
        "    https://arxiv.org/abs/1802.05814\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
        "        super(MultiDAE, self).__init__()\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims:\n",
        "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        else:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # h = F.normalize(input)\n",
        "        h = self.drop(input)\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "\n",
        "\n",
        "class MultiVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Container module for Multi-VAE.\n",
        "\n",
        "    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n",
        "    See Variational Autoencoders for Collaborative Filtering\n",
        "    https://arxiv.org/abs/1802.05814\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
        "        super(MultiVAE, self).__init__()\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims:\n",
        "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        else:\n",
        "            self.q_dims = p_dims[::-1] # default: 대칭 구조\n",
        "\n",
        "        # Last dimension of q- network is for mean and variance\n",
        "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
        "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
        "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input):\n",
        "        mu, logvar = self.encode(input)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "    def encode(self, input):\n",
        "        # h = F.normalize(input)\n",
        "        h = self.drop(input)\n",
        "\n",
        "        for i, layer in enumerate(self.q_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.q_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "            else: #\n",
        "                mu = h[:, :self.q_dims[-1]]\n",
        "                logvar = h[:, self.q_dims[-1]:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar): # latent factor(모수) 조정\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std) # std와 동일 모양의 N(0,1)난수생성\n",
        "            return eps.mul(std).add_(mu) # train: 난수*std + mu\n",
        "        else:\n",
        "            return mu # val/test: mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = z\n",
        "        for i, layer in enumerate(self.p_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.p_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.q_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "        for layer in self.p_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
        "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1)) # softmax: multinomial의 loss\n",
        "    # BCE = torch.nn.BCEWithLogitsLoss(reduction='sum')(recon_x, x)\n",
        "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)) # \n",
        "\n",
        "    return BCE + anneal * KLD\n",
        "\n",
        "def loss_function_dae(recon_x, x):\n",
        "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
        "    # BCE = torch.nn.BCEWithLogitsLoss(reduction='sum')(recon_x, x)\n",
        "    return BCE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "7nEfVTktbxa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sparse2torch_sparse(data): # encoder F.normalize에서 대신 활용\n",
        "    \"\"\"\n",
        "    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n",
        "    This is much faster than naive use of torch.FloatTensor(data.toarray())\n",
        "    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n",
        "    \"\"\"\n",
        "    samples = data.shape[0] # n_users\n",
        "    features = data.shape[1] # n_items\n",
        "    coo_data = data.tocoo()\n",
        "    indices = torch.LongTensor([coo_data.row, coo_data.col])\n",
        "    row_norms_inv = 1 / np.sqrt(data.sum(1)) # 유저별로 interaction 수만큼 normalize\n",
        "    # row_norms_inv = 1 / np.linalg.norm(data, axis=1) # 유저별로 interaction 수만큼 normalize\n",
        "    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n",
        "    values = np.array([row2val[r] for r in coo_data.row])\n",
        "    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n",
        "    return torch.FloatTensor(t.to_dense())\n",
        "\n",
        "def naive_sparse2tensor(data):\n",
        "    return torch.FloatTensor(data.toarray())\n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer, is_VAE = False):\n",
        "    # Turn on training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    global update_count\n",
        "\n",
        "    np.random.shuffle(idxlist)\n",
        "\n",
        "    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n",
        "        end_idx = min(start_idx + args.batch_size, N)\n",
        "        data = train_data[idxlist[start_idx:end_idx]] # 여기의 train_data: sparse interaction matrix 형태\n",
        "        data = naive_sparse2tensor(data).to(device)\n",
        "        # data = sparse2torch_sparse(data).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if is_VAE:\n",
        "          if args.total_anneal_steps > 0:\n",
        "            anneal = min(args.anneal_cap,\n",
        "                            1. * update_count / args.total_anneal_steps)\n",
        "          else:\n",
        "              anneal = args.anneal_cap\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          recon_batch, mu, logvar = model(data)\n",
        "\n",
        "          loss = criterion(recon_batch, data, mu, logvar, anneal)\n",
        "        else:\n",
        "          recon_batch = model(data)\n",
        "          loss = criterion(recon_batch, data)\n",
        "\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        update_count += 1\n",
        "\n",
        "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
        "                    'loss {:4.2f}'.format(\n",
        "                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n",
        "                        elapsed * 1000 / args.log_interval,\n",
        "                        train_loss / args.log_interval))\n",
        "\n",
        "\n",
        "            start_time = time.time()\n",
        "            train_loss = 0.0\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n",
        "    # Turn on evaluation mode\n",
        "    model.eval()\n",
        "    global update_count\n",
        "    e_idxlist = list(range(data_tr.shape[0]))\n",
        "    e_N = data_tr.shape[0]\n",
        "    total_val_loss_list = []\n",
        "    n100_list = []\n",
        "    r20_list = []\n",
        "    r50_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, e_N, args.batch_size):\n",
        "            end_idx = min(start_idx + args.batch_size, N)\n",
        "            data = data_tr[e_idxlist[start_idx:end_idx]]\n",
        "            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n",
        "\n",
        "            data_tensor = naive_sparse2tensor(data).to(device)\n",
        "            # data_tensor = sparse2torch_sparse(data).to(device)\n",
        "            if is_VAE :\n",
        "\n",
        "              if args.total_anneal_steps > 0:\n",
        "                  anneal = min(args.anneal_cap,\n",
        "                                1. * update_count / args.total_anneal_steps)\n",
        "              else:\n",
        "                  anneal = args.anneal_cap\n",
        "\n",
        "              recon_batch, mu, logvar = model(data_tensor)\n",
        "\n",
        "              loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n",
        "\n",
        "            else :\n",
        "              recon_batch = model(data_tensor)\n",
        "              loss = criterion(recon_batch, data_tensor)\n",
        "\n",
        "            total_val_loss_list.append(loss.item())\n",
        "\n",
        "            # Exclude examples from training set\n",
        "            recon_batch = recon_batch.cpu().numpy()\n",
        "            recon_batch[data.nonzero()] = -np.inf\n",
        "\n",
        "            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n",
        "            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n",
        "            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n",
        "            # top10 = torch.topk(recon_batch)\n",
        "\n",
        "            n100_list.append(n100)\n",
        "            r20_list.append(r20)\n",
        "            r50_list.append(r50)\n",
        "\n",
        "    n100_list = np.concatenate(n100_list)\n",
        "    r20_list = np.concatenate(r20_list)\n",
        "    r50_list = np.concatenate(r50_list)\n",
        "\n",
        "    return np.nanmean(total_val_loss_list), np.nanmean(n100_list), np.nanmean(r20_list), np.nanmean(r50_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOsCJbb_X9gl"
      },
      "source": [
        "## Metric 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "zxNtit6vbxa-"
      },
      "outputs": [],
      "source": [
        "import bottleneck as bn\n",
        "import numpy as np\n",
        "\n",
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    Normalized Discounted Cumulative Gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG\n",
        "\n",
        "\n",
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDD7lD7sHcnH"
      },
      "source": [
        "## MultiDAE 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "WLYyTwToX4fm"
      },
      "outputs": [],
      "source": [
        "\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "n_items = loader.load_n_items()\n",
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader.load_data('test')\n",
        "\n",
        "N = train_data.shape[0]\n",
        "idxlist = list(range(N))\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "p_dims = [200, 600, n_items]\n",
        "model = MultiDAE(p_dims).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
        "criterion = loss_function_dae\n",
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "best_n100 = -np.inf\n",
        "update_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rOEDs2Lbxa-",
        "outputId": "ccbcf453-8276-498e-85d8-f44a83687c6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1.66s | valid loss 259683.58 | n100 0.262 | r20 0.192 | r50 0.238\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1.50s | valid loss 253584.77 | n100 0.262 | r20 0.191 | r50 0.238\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1.53s | valid loss 236254.58 | n100 0.263 | r20 0.193 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1.53s | valid loss 231153.55 | n100 0.264 | r20 0.191 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1.62s | valid loss 229580.88 | n100 0.264 | r20 0.194 | r50 0.241\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1.60s | valid loss 224403.30 | n100 0.274 | r20 0.202 | r50 0.251\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1.61s | valid loss 222482.88 | n100 0.280 | r20 0.207 | r50 0.257\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1.56s | valid loss 216268.48 | n100 0.304 | r20 0.229 | r50 0.278\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1.56s | valid loss 212178.99 | n100 0.311 | r20 0.234 | r50 0.285\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1.64s | valid loss 208338.39 | n100 0.324 | r20 0.244 | r50 0.297\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1.63s | valid loss 205906.56 | n100 0.330 | r20 0.247 | r50 0.301\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1.65s | valid loss 204463.88 | n100 0.334 | r20 0.251 | r50 0.306\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1.62s | valid loss 202732.46 | n100 0.339 | r20 0.255 | r50 0.310\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1.62s | valid loss 202766.08 | n100 0.342 | r20 0.258 | r50 0.314\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1.63s | valid loss 198696.98 | n100 0.349 | r20 0.263 | r50 0.319\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1.62s | valid loss 196021.28 | n100 0.359 | r20 0.273 | r50 0.329\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1.68s | valid loss 194700.95 | n100 0.366 | r20 0.279 | r50 0.334\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1.68s | valid loss 193072.54 | n100 0.371 | r20 0.282 | r50 0.339\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1.62s | valid loss 192554.23 | n100 0.374 | r20 0.285 | r50 0.342\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1.65s | valid loss 190882.79 | n100 0.378 | r20 0.288 | r50 0.345\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1.64s | valid loss 190004.75 | n100 0.382 | r20 0.292 | r50 0.350\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1.65s | valid loss 188671.34 | n100 0.388 | r20 0.297 | r50 0.355\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1.66s | valid loss 187192.39 | n100 0.390 | r20 0.299 | r50 0.357\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1.65s | valid loss 186746.80 | n100 0.391 | r20 0.299 | r50 0.358\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1.74s | valid loss 186610.84 | n100 0.395 | r20 0.302 | r50 0.360\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 1.68s | valid loss 185055.19 | n100 0.396 | r20 0.303 | r50 0.363\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 1.59s | valid loss 183851.92 | n100 0.400 | r20 0.307 | r50 0.367\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 1.63s | valid loss 184604.08 | n100 0.401 | r20 0.307 | r50 0.369\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 1.58s | valid loss 183167.09 | n100 0.403 | r20 0.308 | r50 0.369\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 1.71s | valid loss 182759.10 | n100 0.407 | r20 0.312 | r50 0.373\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 1.64s | valid loss 182004.63 | n100 0.408 | r20 0.314 | r50 0.373\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 1.63s | valid loss 181693.41 | n100 0.408 | r20 0.315 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 1.73s | valid loss 180374.49 | n100 0.411 | r20 0.317 | r50 0.377\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 1.63s | valid loss 179890.89 | n100 0.412 | r20 0.317 | r50 0.378\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 1.65s | valid loss 180018.95 | n100 0.415 | r20 0.320 | r50 0.380\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 1.59s | valid loss 178838.96 | n100 0.417 | r20 0.323 | r50 0.381\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 1.64s | valid loss 179175.21 | n100 0.418 | r20 0.325 | r50 0.382\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 1.63s | valid loss 179060.30 | n100 0.420 | r20 0.324 | r50 0.383\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 1.67s | valid loss 179133.11 | n100 0.422 | r20 0.327 | r50 0.385\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 1.66s | valid loss 177047.12 | n100 0.423 | r20 0.327 | r50 0.386\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 1.61s | valid loss 177813.74 | n100 0.426 | r20 0.331 | r50 0.388\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 1.70s | valid loss 176721.97 | n100 0.427 | r20 0.331 | r50 0.389\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 1.72s | valid loss 175898.08 | n100 0.427 | r20 0.331 | r50 0.389\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 1.74s | valid loss 175241.71 | n100 0.428 | r20 0.331 | r50 0.390\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 1.59s | valid loss 174903.49 | n100 0.428 | r20 0.332 | r50 0.390\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 1.59s | valid loss 174809.21 | n100 0.429 | r20 0.333 | r50 0.391\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 1.67s | valid loss 174592.35 | n100 0.431 | r20 0.333 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 1.74s | valid loss 173711.42 | n100 0.431 | r20 0.334 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 1.71s | valid loss 174802.64 | n100 0.432 | r20 0.334 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 1.65s | valid loss 174309.80 | n100 0.432 | r20 0.336 | r50 0.394\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 1.62s | valid loss 173718.97 | n100 0.433 | r20 0.336 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 1.60s | valid loss 174163.81 | n100 0.434 | r20 0.337 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 1.63s | valid loss 172252.99 | n100 0.435 | r20 0.337 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 1.70s | valid loss 172633.96 | n100 0.434 | r20 0.336 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 1.71s | valid loss 174462.39 | n100 0.435 | r20 0.337 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 1.63s | valid loss 173156.63 | n100 0.438 | r20 0.340 | r50 0.398\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 1.64s | valid loss 172578.28 | n100 0.436 | r20 0.340 | r50 0.399\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 1.59s | valid loss 172582.96 | n100 0.438 | r20 0.340 | r50 0.399\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 1.66s | valid loss 171257.50 | n100 0.437 | r20 0.339 | r50 0.400\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 168874.17 | n100 0.44 | r20 0.34 | r50 0.40\n",
            "=========================================================================================\n",
            "best epoch: 58\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, args.epochs+40):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, criterion, optimizer, is_VAE=False)\n",
        "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "\n",
        "\n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_n100:\n",
        "        with open(args.save, 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_n100 = n100\n",
        "        best_epoch = epoch\n",
        "\n",
        "\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
        "print('=' * 89)\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1QjCbMBXw4v"
      },
      "source": [
        "## MultiVAE 테스트 (TODO)\n",
        "\n",
        "위의 MultiVAE 모델 코드, train, evaluate 함수를 완성하여, 아래 훈련 코드가 정상적으로 동작하도록 해보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "78zFFNzgbxa_"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "n_items = loader.load_n_items()\n",
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader.load_data('test')\n",
        "\n",
        "N = train_data.shape[0] # n_users\n",
        "idxlist = list(range(N)) # 유저들 묶음을 batch로\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "p_dims = [200, 600, n_items]\n",
        "model = MultiVAE(p_dims).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n",
        "criterion = loss_function_vae\n",
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "best_n100 = -np.inf\n",
        "update_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoUFwndCvvtp",
        "outputId": "3ec0ad84-6ac1-43f7-9ad1-8de61e1307d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1.68s | valid loss 257870.44 | n100 0.259 | r20 0.191 | r50 0.236\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1.57s | valid loss 244882.44 | n100 0.262 | r20 0.189 | r50 0.238\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1.61s | valid loss 237222.62 | n100 0.260 | r20 0.190 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1.55s | valid loss 234359.27 | n100 0.263 | r20 0.190 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1.66s | valid loss 232969.33 | n100 0.263 | r20 0.192 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1.62s | valid loss 231792.95 | n100 0.262 | r20 0.193 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1.60s | valid loss 229369.92 | n100 0.264 | r20 0.195 | r50 0.241\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1.57s | valid loss 227265.66 | n100 0.270 | r20 0.201 | r50 0.248\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1.51s | valid loss 226283.13 | n100 0.273 | r20 0.201 | r50 0.250\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1.57s | valid loss 224913.71 | n100 0.277 | r20 0.204 | r50 0.253\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1.67s | valid loss 223438.55 | n100 0.279 | r20 0.206 | r50 0.257\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1.65s | valid loss 220578.03 | n100 0.293 | r20 0.218 | r50 0.267\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1.63s | valid loss 218455.54 | n100 0.301 | r20 0.226 | r50 0.275\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1.71s | valid loss 215390.25 | n100 0.308 | r20 0.231 | r50 0.282\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1.58s | valid loss 213192.98 | n100 0.314 | r20 0.235 | r50 0.288\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1.55s | valid loss 211420.12 | n100 0.318 | r20 0.240 | r50 0.290\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1.62s | valid loss 209936.40 | n100 0.323 | r20 0.241 | r50 0.294\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1.79s | valid loss 209086.19 | n100 0.327 | r20 0.244 | r50 0.298\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1.57s | valid loss 207423.29 | n100 0.332 | r20 0.252 | r50 0.303\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1.67s | valid loss 207235.53 | n100 0.335 | r20 0.254 | r50 0.305\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1.62s | valid loss 205082.08 | n100 0.339 | r20 0.256 | r50 0.309\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1.63s | valid loss 205103.15 | n100 0.340 | r20 0.257 | r50 0.311\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1.66s | valid loss 203284.01 | n100 0.345 | r20 0.261 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1.74s | valid loss 202348.43 | n100 0.347 | r20 0.263 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1.71s | valid loss 201565.87 | n100 0.349 | r20 0.266 | r50 0.320\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 1.58s | valid loss 200390.85 | n100 0.354 | r20 0.270 | r50 0.324\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 1.66s | valid loss 199629.22 | n100 0.356 | r20 0.271 | r50 0.324\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 1.73s | valid loss 199495.28 | n100 0.361 | r20 0.276 | r50 0.330\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 1.64s | valid loss 199266.15 | n100 0.362 | r20 0.274 | r50 0.330\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 1.57s | valid loss 197276.33 | n100 0.364 | r20 0.277 | r50 0.332\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 1.58s | valid loss 196141.80 | n100 0.366 | r20 0.277 | r50 0.334\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 1.49s | valid loss 195886.70 | n100 0.372 | r20 0.283 | r50 0.338\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 1.60s | valid loss 194509.86 | n100 0.372 | r20 0.283 | r50 0.338\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 1.61s | valid loss 194415.50 | n100 0.375 | r20 0.284 | r50 0.340\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 1.57s | valid loss 193393.41 | n100 0.379 | r20 0.288 | r50 0.346\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 1.67s | valid loss 192620.80 | n100 0.382 | r20 0.292 | r50 0.348\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 1.54s | valid loss 190974.59 | n100 0.384 | r20 0.294 | r50 0.352\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 1.69s | valid loss 190578.31 | n100 0.387 | r20 0.297 | r50 0.355\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 1.65s | valid loss 189690.88 | n100 0.388 | r20 0.298 | r50 0.356\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 1.72s | valid loss 188485.09 | n100 0.392 | r20 0.301 | r50 0.359\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 1.72s | valid loss 188613.91 | n100 0.395 | r20 0.303 | r50 0.361\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 1.64s | valid loss 187533.64 | n100 0.395 | r20 0.304 | r50 0.362\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 1.69s | valid loss 187454.25 | n100 0.400 | r20 0.308 | r50 0.366\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 1.70s | valid loss 185102.73 | n100 0.402 | r20 0.310 | r50 0.368\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 1.59s | valid loss 184462.29 | n100 0.404 | r20 0.312 | r50 0.370\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 1.61s | valid loss 183196.74 | n100 0.408 | r20 0.313 | r50 0.374\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 1.64s | valid loss 182096.70 | n100 0.410 | r20 0.316 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 1.78s | valid loss 182216.62 | n100 0.412 | r20 0.318 | r50 0.376\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 1.73s | valid loss 180448.68 | n100 0.415 | r20 0.321 | r50 0.379\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 1.73s | valid loss 179923.16 | n100 0.418 | r20 0.323 | r50 0.381\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 1.68s | valid loss 178872.23 | n100 0.420 | r20 0.325 | r50 0.385\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 1.64s | valid loss 178255.58 | n100 0.424 | r20 0.329 | r50 0.388\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 1.73s | valid loss 176128.51 | n100 0.426 | r20 0.331 | r50 0.388\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 1.66s | valid loss 175767.60 | n100 0.429 | r20 0.332 | r50 0.392\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 1.62s | valid loss 174218.63 | n100 0.432 | r20 0.336 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 1.58s | valid loss 174354.38 | n100 0.434 | r20 0.339 | r50 0.397\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 1.59s | valid loss 173144.85 | n100 0.437 | r20 0.341 | r50 0.401\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 1.67s | valid loss 171819.12 | n100 0.440 | r20 0.343 | r50 0.402\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 1.71s | valid loss 169900.47 | n100 0.441 | r20 0.344 | r50 0.403\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 166396.17 | n100 0.44 | r20 0.34 | r50 0.41\n",
            "=========================================================================================\n",
            "best epoch: 59\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, args.epochs + 40):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, criterion, optimizer, is_VAE=True)\n",
        "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "\n",
        "\n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_n100:\n",
        "        with open(args.save, 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_n100 = n100\n",
        "        best_epoch = epoch\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
        "print('=' * 89)\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xBh0Mrcn6Af"
      },
      "source": [
        "## Required Package\n",
        "\n",
        "- numpy==1.23.5\n",
        "- pandas==1.5.3\n",
        "- torch==2.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQjnnLZ-Jf5b"
      },
      "source": [
        "###**콘텐츠 라이선스**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference\n",
        "\n",
        "전체 학습 -> inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_N = raw_data.user.nunique()\n",
        "idx_list = np.arange(total_N)\n",
        "\n",
        "id2show = {v:k for k,v in show2id.items()}\n",
        "id2profile = {v:k for k,v in profile2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'model_total.pt'"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "args.save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inference(model, criterion, data, is_VAE=False):\n",
        "   \n",
        "# Load the best saved model.\n",
        "    with open(args.save, 'rb') as f:\n",
        "      model = torch.load(f)\n",
        "    \n",
        "    # turn on eval mode\n",
        "    model.eval()\n",
        "    global update_count\n",
        "    idxlist = list(range(data.shape[0]))\n",
        "    N = data.shape[0]\n",
        "    total_topk = []\n",
        "    result = pd.DataFrame()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, N, args.batch_size):\n",
        "            end_idx = min(start_idx + args.batch_size, N)\n",
        "            batch = data[idxlist[start_idx:end_idx]]\n",
        "\n",
        "            # data_tensor = naive_sparse2tensor(data).to(device)\n",
        "            data_tensor = sparse2torch_sparse(batch).to(device)\n",
        "            if is_VAE :\n",
        "\n",
        "              if args.total_anneal_steps > 0:\n",
        "                  anneal = min(args.anneal_cap,\n",
        "                                1. * update_count / args.total_anneal_steps)\n",
        "              else:\n",
        "                  anneal = args.anneal_cap\n",
        "\n",
        "              recon_batch, mu, logvar = model(data_tensor)\n",
        "\n",
        "            else :\n",
        "              recon_batch = model(data_tensor)\n",
        "\n",
        "            # Exclude examples from training set\n",
        "            recon_batch[batch.nonzero()] = -1e9\n",
        "\n",
        "            topk = torch.topk(input=recon_batch, k=10)\n",
        "            batch_topk = list(topk.indices.reshape(-1).detach().cpu().numpy())\n",
        "          \n",
        "            total_topk.extend(batch_topk)\n",
        "\n",
        "\n",
        "    result['user'] = np.repeat(np.arange(31360),10)\n",
        "    result['item'] = total_topk\n",
        "\n",
        "    result['user'] = result['user'].apply(lambda x: id2profile[x])\n",
        "    result['item'] = result['item'].apply(lambda x: id2show[x])\n",
        "    \n",
        "    return result.sort_values('user').reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrain(model, criterion, optimizer, train_data=data_inf, is_VAE = False):\n",
        "    # Turn on training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    global update_count\n",
        "    N = train_data.shape[0]\n",
        "    idxlist = np.arange(N)\n",
        "\n",
        "    np.random.shuffle(idxlist)\n",
        "\n",
        "    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n",
        "        end_idx = min(start_idx + args.batch_size, N)\n",
        "        batch = train_data[idxlist[start_idx:end_idx]] # 여기의 train_data: sparse interaction matrix 형태\n",
        "        data = naive_sparse2tensor(batch).to(device)\n",
        "        # data = sparse2torch_sparse(batch).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if is_VAE:\n",
        "          if args.total_anneal_steps > 0:\n",
        "            anneal = min(args.anneal_cap,\n",
        "                            1. * update_count / args.total_anneal_steps)\n",
        "          else:\n",
        "              anneal = args.anneal_cap\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          recon_batch, mu, logvar = model(data)\n",
        "\n",
        "          loss = criterion(recon_batch, data, mu, logvar, anneal)\n",
        "        else:\n",
        "          recon_batch = model(data)\n",
        "          loss = criterion(recon_batch, data)\n",
        "\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        update_count += 1\n",
        "\n",
        "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
        "                    'loss {:4.2f}'.format(\n",
        "                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n",
        "                        elapsed * 1000 / args.log_interval,\n",
        "                        train_loss / args.log_interval))\n",
        "\n",
        "\n",
        "            start_time = time.time()\n",
        "            train_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_dims = [200, 600, n_items]\n",
        "model = MultiVAE(p_dims).to(device)\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n",
        "criterion = loss_function_vae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1.62s | valid loss 257006.02 | n100 0.261 | r20 0.191 | r50 0.236\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1.56s | valid loss 241311.42 | n100 0.263 | r20 0.191 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1.49s | valid loss 235747.03 | n100 0.262 | r20 0.190 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1.51s | valid loss 233817.99 | n100 0.263 | r20 0.192 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1.53s | valid loss 232515.37 | n100 0.263 | r20 0.191 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1.59s | valid loss 230377.44 | n100 0.266 | r20 0.194 | r50 0.241\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1.65s | valid loss 228247.84 | n100 0.270 | r20 0.199 | r50 0.246\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1.48s | valid loss 226076.11 | n100 0.272 | r20 0.202 | r50 0.250\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1.59s | valid loss 224181.16 | n100 0.277 | r20 0.203 | r50 0.253\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1.55s | valid loss 222173.60 | n100 0.284 | r20 0.209 | r50 0.261\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1.52s | valid loss 218874.01 | n100 0.299 | r20 0.225 | r50 0.275\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1.67s | valid loss 214986.12 | n100 0.313 | r20 0.236 | r50 0.287\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1.62s | valid loss 212032.61 | n100 0.322 | r20 0.242 | r50 0.294\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1.58s | valid loss 209220.15 | n100 0.326 | r20 0.247 | r50 0.299\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1.63s | valid loss 208625.19 | n100 0.331 | r20 0.249 | r50 0.303\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1.54s | valid loss 206837.45 | n100 0.335 | r20 0.253 | r50 0.305\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1.70s | valid loss 205307.43 | n100 0.338 | r20 0.255 | r50 0.309\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1.73s | valid loss 203582.67 | n100 0.344 | r20 0.259 | r50 0.312\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1.68s | valid loss 202094.72 | n100 0.346 | r20 0.260 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1.64s | valid loss 201125.92 | n100 0.352 | r20 0.267 | r50 0.322\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1.58s | valid loss 200763.41 | n100 0.356 | r20 0.269 | r50 0.324\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1.64s | valid loss 198083.63 | n100 0.361 | r20 0.274 | r50 0.329\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1.62s | valid loss 197762.70 | n100 0.364 | r20 0.275 | r50 0.334\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1.64s | valid loss 195684.05 | n100 0.367 | r20 0.279 | r50 0.335\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1.67s | valid loss 195286.76 | n100 0.369 | r20 0.280 | r50 0.338\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 1.57s | valid loss 194224.64 | n100 0.371 | r20 0.283 | r50 0.339\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 1.69s | valid loss 194096.60 | n100 0.374 | r20 0.285 | r50 0.341\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 1.64s | valid loss 193755.89 | n100 0.374 | r20 0.285 | r50 0.342\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 1.68s | valid loss 192048.51 | n100 0.378 | r20 0.288 | r50 0.345\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 1.65s | valid loss 191538.78 | n100 0.380 | r20 0.291 | r50 0.348\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 1.60s | valid loss 190422.60 | n100 0.384 | r20 0.293 | r50 0.351\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 1.69s | valid loss 189737.52 | n100 0.386 | r20 0.295 | r50 0.352\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 1.64s | valid loss 189581.29 | n100 0.388 | r20 0.297 | r50 0.355\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 1.69s | valid loss 188167.28 | n100 0.391 | r20 0.301 | r50 0.357\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 1.67s | valid loss 187711.42 | n100 0.395 | r20 0.302 | r50 0.360\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 1.64s | valid loss 185742.16 | n100 0.397 | r20 0.305 | r50 0.365\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 1.64s | valid loss 185476.23 | n100 0.402 | r20 0.308 | r50 0.368\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 1.60s | valid loss 183350.55 | n100 0.404 | r20 0.312 | r50 0.371\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 1.66s | valid loss 182391.61 | n100 0.407 | r20 0.312 | r50 0.374\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 1.58s | valid loss 182151.28 | n100 0.411 | r20 0.316 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 1.59s | valid loss 181296.33 | n100 0.414 | r20 0.320 | r50 0.379\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 1.65s | valid loss 178762.14 | n100 0.418 | r20 0.323 | r50 0.382\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 1.62s | valid loss 178244.50 | n100 0.421 | r20 0.326 | r50 0.387\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 1.73s | valid loss 177284.66 | n100 0.425 | r20 0.328 | r50 0.389\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 1.61s | valid loss 175915.60 | n100 0.428 | r20 0.334 | r50 0.391\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 1.68s | valid loss 175697.83 | n100 0.430 | r20 0.336 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 1.64s | valid loss 174141.16 | n100 0.435 | r20 0.339 | r50 0.395\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 1.64s | valid loss 172049.71 | n100 0.436 | r20 0.341 | r50 0.398\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 1.69s | valid loss 171542.51 | n100 0.439 | r20 0.343 | r50 0.400\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 1.66s | valid loss 170064.88 | n100 0.441 | r20 0.345 | r50 0.403\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 1.64s | valid loss 169622.47 | n100 0.443 | r20 0.346 | r50 0.404\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 1.71s | valid loss 169119.76 | n100 0.443 | r20 0.347 | r50 0.405\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 1.59s | valid loss 167051.82 | n100 0.447 | r20 0.349 | r50 0.408\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 1.68s | valid loss 166551.84 | n100 0.448 | r20 0.351 | r50 0.409\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 1.57s | valid loss 165562.39 | n100 0.448 | r20 0.352 | r50 0.411\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 1.72s | valid loss 165819.22 | n100 0.451 | r20 0.354 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 1.64s | valid loss 164835.88 | n100 0.452 | r20 0.356 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 1.60s | valid loss 162825.06 | n100 0.452 | r20 0.356 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 1.71s | valid loss 161969.43 | n100 0.453 | r20 0.356 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 158710.63 | n100 0.45 | r20 0.35 | r50 0.42\n",
            "=========================================================================================\n",
            "best epoch: 59\n"
          ]
        }
      ],
      "source": [
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader._load_tr_te_data('test')\n",
        "data_inf = loader.load_data('inference')\n",
        "\n",
        "N = train_data.shape[0]\n",
        "idx_list = np.arange(N)\n",
        "\n",
        "best_n100 = -np.inf\n",
        "for epoch in range(1, args.epochs + 40):\n",
        "    epoch_start_time = time.time()\n",
        "    # retrain(model, criterion, optimizer, data_inf, is_VAE=True)\n",
        "    train(model, criterion, optimizer, is_VAE=True)\n",
        "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "\n",
        "\n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_n100:\n",
        "        with open('model_total.pt', 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_n100 = n100\n",
        "        best_epoch=epoch\n",
        "\n",
        "\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
        "print('=' * 89)\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        }
      ],
      "source": [
        "args.save='model_total.pt'\n",
        "result = inference(model, criterion, data_inf, is_VAE=True)\n",
        "result.to_csv('multi-vae.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>2329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>72998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>32587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>34405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313595</th>\n",
              "      <td>138493</td>\n",
              "      <td>8961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313596</th>\n",
              "      <td>138493</td>\n",
              "      <td>1270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313597</th>\n",
              "      <td>138493</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313598</th>\n",
              "      <td>138493</td>\n",
              "      <td>32587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313599</th>\n",
              "      <td>138493</td>\n",
              "      <td>4995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>313600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user   item\n",
              "0           11   2329\n",
              "1           11  72998\n",
              "2           11  32587\n",
              "3           11  34405\n",
              "4           11   4370\n",
              "...        ...    ...\n",
              "313595  138493   8961\n",
              "313596  138493   1270\n",
              "313597  138493   2012\n",
              "313598  138493  32587\n",
              "313599  138493   4995\n",
              "\n",
              "[313600 rows x 2 columns]"
            ]
          },
          "execution_count": 408,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>5218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>8861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>3986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>2054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313595</th>\n",
              "      <td>138493</td>\n",
              "      <td>4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313596</th>\n",
              "      <td>138493</td>\n",
              "      <td>589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313597</th>\n",
              "      <td>138493</td>\n",
              "      <td>2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313598</th>\n",
              "      <td>138493</td>\n",
              "      <td>33615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313599</th>\n",
              "      <td>138493</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>313600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user   item\n",
              "0           11   5218\n",
              "1           11   8861\n",
              "2           11   3986\n",
              "3           11   2054\n",
              "4           11   4370\n",
              "...        ...    ...\n",
              "313595  138493   4370\n",
              "313596  138493    589\n",
              "313597  138493   2011\n",
              "313598  138493  33615\n",
              "313599  138493    593\n",
              "\n",
              "[313600 rows x 2 columns]"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
