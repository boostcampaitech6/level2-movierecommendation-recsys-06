{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQG9hL8-UQUP"
      },
      "source": [
        "# Multi-VAE\n",
        "\n",
        "이번 미션에서는 [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)에서 제안된 Multi-VAE 기반의 협업 필터링을 구현해보도록 하겠습니다. 다양한 Auto-Encoder 기반의 협업필터링이 제안된 이후에, 가장 강력하다고 평가받는 VAE 기반의 협업 필터링을 이해하는 시간을 갖도록 하겠습니다.\n",
        "\n",
        "- 이 미션은 다음 [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다. 바로 코드를 확인해보지 마시고, 최대한 직접 작성을 해보세요!\n",
        "- 이 미션에서 중요한 부분은 모델 부분입니다. 데이터 전처리 부분은 가볍게 훑어 보시고, 모델 부분을 집중해주세요!\n",
        "\n",
        "### 변경사항\n",
        "1. label을 확률값$\\frac{1}{\\sqrt{n}}$로 조정한 soft label 적용\n",
        "    - 이 과정에서 전처리 함수 sparse2tensor로 조정 (이게 왜 다항분포??)\n",
        "    - 각자 독립인 logistic loss도 실험 예정 -> 다항분포 해결은 이걸로 해결되는건가 싶기도 함\n",
        "    - normalize 덜 smooth하게도 고려 중\n",
        "\n",
        "\n",
        "2. tr_uid: userplays.index -> userplays.user 로 조정 (전체 데이터 셋에 등장하지도 않는 유저번호0번 같은 유령유저가 데이터셋에 포함됨)\n",
        "    - 데이터셋에 모든 interaction 0인 유저들 넘쳐났었음\n",
        "    - normalize 시 divide by 0 해결\n",
        "\n",
        "3. 내일 아침 할거\n",
        "    - userid 질문\n",
        "    - 기본 inference 구현\n",
        "    - public 제출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CfnRw7U59C"
      },
      "source": [
        "## 1. 초기 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylGzdjCI2ujg",
        "outputId": "09aaad72-83a5-4420-d27a-c5910250328e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bottleneck in /opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages (from bottleneck) (1.26.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# bottleneck은 C로 작성된 빠른 NumPy 배열 함수 모음입니다.\n",
        "!pip install bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bQj6k1mSbxaz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import argparse\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = pd.read_csv('../../data/train/pro_sg/validation_te.csv')\n",
        "b = pd.read_csv('../../data/train/pro_sg/validation_tr.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(98001, 397924)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.shape[0], b.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>sid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26554</td>\n",
              "      <td>3025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26554</td>\n",
              "      <td>1681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26554</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26554</td>\n",
              "      <td>3190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26554</td>\n",
              "      <td>3301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97996</th>\n",
              "      <td>26934</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97997</th>\n",
              "      <td>26934</td>\n",
              "      <td>1126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97998</th>\n",
              "      <td>26934</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97999</th>\n",
              "      <td>26934</td>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98000</th>\n",
              "      <td>26934</td>\n",
              "      <td>1792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98001 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         uid   sid\n",
              "0      26554  3025\n",
              "1      26554  1681\n",
              "2      26554   201\n",
              "3      26554  3190\n",
              "4      26554  3301\n",
              "...      ...   ...\n",
              "97996  26934   228\n",
              "97997  26934  1126\n",
              "97998  26934   235\n",
              "97999  26934   209\n",
              "98000  26934  1792\n",
              "\n",
              "[98001 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>sid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26554</td>\n",
              "      <td>440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26554</td>\n",
              "      <td>741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26554</td>\n",
              "      <td>1407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26554</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26554</td>\n",
              "      <td>1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397919</th>\n",
              "      <td>26934</td>\n",
              "      <td>760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397920</th>\n",
              "      <td>26934</td>\n",
              "      <td>697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397921</th>\n",
              "      <td>26934</td>\n",
              "      <td>3245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397922</th>\n",
              "      <td>26934</td>\n",
              "      <td>1369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397923</th>\n",
              "      <td>26934</td>\n",
              "      <td>3691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>397924 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          uid   sid\n",
              "0       26554   440\n",
              "1       26554   741\n",
              "2       26554  1407\n",
              "3       26554   193\n",
              "4       26554  1041\n",
              "...       ...   ...\n",
              "397919  26934   760\n",
              "397920  26934   697\n",
              "397921  26934  3245\n",
              "397922  26934  1369\n",
              "397923  26934  3691\n",
              "\n",
              "[397924 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMWYLPFIjon8"
      },
      "source": [
        "## 데이터 다운로드\n",
        "이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요.\n",
        "- 데이터 URL은 변경될 수 있습니다.\n",
        "- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = '../../data/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ3W0udmbxa3",
        "outputId": "e06b80ea-6ed1-4406-e03c-e9bfe67f9946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 각종 파라미터 세팅\n",
        "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
        "\n",
        "\n",
        "parser.add_argument('--data', type=str, default=data_dir,\n",
        "                    help='Movielens dataset location')\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=1e-3,\n",
        "                    help='initial learning rate')\n",
        "parser.add_argument('--wd', type=float, default=0.00,\n",
        "                    help='weight decay coefficient')\n",
        "parser.add_argument('--batch_size', type=int, default=500,\n",
        "                    help='batch size')\n",
        "parser.add_argument('--epochs', type=int, default=20,\n",
        "                    help='upper epoch limit')\n",
        "parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
        "                    help='the total number of gradient updates for annealing')\n",
        "parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
        "                    help='largest annealing parameter')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--cuda', action='store_true',\n",
        "                    help='use CUDA')\n",
        "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
        "                    help='report interval')\n",
        "parser.add_argument('--save', type=str, default='model.pt',\n",
        "                    help='path to save the final model')\n",
        "args = parser.parse_args([])\n",
        "\n",
        "# Set the random seed manually for reproductibility.\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
        "if torch.cuda.is_available():\n",
        "    args.cuda = True\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o1fvXqFWE_G"
      },
      "source": [
        "##2. 데이터 전처리\n",
        "\n",
        "이 부분에서 진행되는 과정은 저희가 일반적으로 알고있는 MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. 전처리 과정의 다양한 옵션들을 구성하기 위해 약간 복잡하게 되었지만,\n",
        "결과적으로는, 유저들의 특정한 아이템들을 따로 분리를 해서, 그 분리된 값을 모델이 예측할 수 있냐를 확인하기 위한 전처리 과정이라고 보시면 되겠습니다.\n",
        "실제로 나오는 데이터셋을 확인하면 더욱 이해가 빠를것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.235294117647059"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a,b = 6800*600 + 600*600*4 + 600*200*2, 200*200 + 200*6800\n",
        "\n",
        "a/b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cgvNoy1Ybxa6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "\n",
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "\n",
        "    return count\n",
        "\n",
        "# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상)\n",
        "# 데이터만을 추출할 때 사용하는 함수입니다.\n",
        "# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n",
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'item')\n",
        "        tp = tp[tp['item'].isin(itemcount[itemcount['size'] >= min_sc]['item'])]\n",
        "\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'user')\n",
        "        tp = tp[tp['user'].isin(usercount[usercount['size'] >= min_uc]['user'])]\n",
        "\n",
        "    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n",
        "    return tp, usercount, itemcount\n",
        "\n",
        "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n",
        "#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n",
        "#확인하기 위함입니다.\n",
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('user')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for _, group in data_grouped_by_user:\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "\n",
        "    return data_tr, data_te\n",
        "\n",
        "def numerize(tp, profile2id, show2id):\n",
        "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
        "    sid = tp['item'].apply(lambda x: show2id[x])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVFoRHrmVQsp",
        "outputId": "c96f119e-524e-4329-b89d-ed745e0eaf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load and Preprocess Movielens dataset\n",
            "원본 데이터\n",
            "            user   item        time\n",
            "0            11   4643  1230782529\n",
            "1            11    170  1230782534\n",
            "2            11    531  1230782539\n",
            "3            11    616  1230782542\n",
            "4            11   2140  1230782563\n",
            "...         ...    ...         ...\n",
            "5154466  138493  44022  1260209449\n",
            "5154467  138493   4958  1260209482\n",
            "5154468  138493  68319  1260209720\n",
            "5154469  138493  40819  1260209726\n",
            "5154470  138493  27311  1260209807\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n",
            "            user   item        time\n",
            "0            11   4643  1230782529\n",
            "1            11    170  1230782534\n",
            "2            11    531  1230782539\n",
            "3            11    616  1230782542\n",
            "4            11   2140  1230782563\n",
            "...         ...    ...         ...\n",
            "5154466  138493  44022  1260209449\n",
            "5154467  138493   4958  1260209482\n",
            "5154468  138493  68319  1260209720\n",
            "5154469  138493  40819  1260209726\n",
            "5154470  138493  27311  1260209807\n",
            "\n",
            "[5154471 rows x 3 columns]\n",
            "유저별 리뷰수\n",
            "          user  size\n",
            "0          11   376\n",
            "1          14   180\n",
            "2          18    77\n",
            "3          25    91\n",
            "4          31   154\n",
            "...       ...   ...\n",
            "31355  138473    63\n",
            "31356  138475   124\n",
            "31357  138486   137\n",
            "31358  138492    68\n",
            "31359  138493   314\n",
            "\n",
            "[31360 rows x 2 columns]\n",
            "아이템별 리뷰수\n",
            "         item   size\n",
            "0          1  12217\n",
            "1          2   3364\n",
            "2          3    734\n",
            "3          4     43\n",
            "4          5    590\n",
            "...      ...    ...\n",
            "6802  118700     54\n",
            "6803  118900     60\n",
            "6804  118997     52\n",
            "6805  119141    122\n",
            "6806  119145     78\n",
            "\n",
            "[6807 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Load and Preprocess Movielens dataset\")\n",
        "# Load Data\n",
        "DATA_DIR = args.data\n",
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n",
        "print(\"원본 데이터\\n\", raw_data)\n",
        "\n",
        "# Filter Data\n",
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n",
        "#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n",
        "print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n",
        "\n",
        "print(\"유저별 리뷰수\\n\",user_activity)\n",
        "print(\"아이템별 리뷰수\\n\",item_popularity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(np.log(raw_data.groupby('user').item.count()), bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "148.4131591025766"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.exp(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5154471, 3)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T1dTsWUrffP",
        "outputId": "6ceb7d17-d6e8-4a44-cafa-f3f84cadc6fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(BEFORE) unique_uid: 0            11\n",
            "1            14\n",
            "2            18\n",
            "3            25\n",
            "4            31\n",
            "          ...  \n",
            "31355    138473\n",
            "31356    138475\n",
            "31357    138486\n",
            "31358    138492\n",
            "31359    138493\n",
            "Name: user, Length: 31360, dtype: int64\n",
            "(AFTER) unique_uid: 6392      27968\n",
            "15438     67764\n",
            "603        2581\n",
            "18877     82969\n",
            "31197    137831\n",
            "          ...  \n",
            "30685    135379\n",
            "28589    125855\n",
            "9580      41891\n",
            "3571      15720\n",
            "3861      17029\n",
            "Name: user, Length: 31360, dtype: int64\n",
            "훈련 데이터에 사용될 사용자 수: 28360\n",
            "검증 데이터에 사용될 사용자 수: 0\n",
            "테스트 데이터에 사용될 사용자 수: 3000\n"
          ]
        }
      ],
      "source": [
        "# Shuffle User Indices\n",
        "unique_uid = user_activity.user # 아무리봐도 여기 이상한데?\n",
        "print(\"(BEFORE) unique_uid:\",unique_uid)\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]\n",
        "print(\"(AFTER) unique_uid:\",unique_uid)\n",
        "\n",
        "n_users = unique_uid.size #31360\n",
        "n_heldout_users = 3000\n",
        "\n",
        "\n",
        "# Split Train/Validation/Test User Indices\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # val 3000명\n",
        "te_users = unique_uid[(n_users - n_heldout_users):] # test 3000명\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users): (n_users - n_heldout_users)] # val 3000명\n",
        "\n",
        "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
        "print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n",
        "print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n",
        "print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'raw_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_data\u001b[39m.\u001b[39minfo()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
          ]
        }
      ],
      "source": [
        "raw_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yBsRCRqtPz6",
        "outputId": "fa16f7f7-09c9-42f3-b350-87168c60d12a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[382], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m vad_plays \u001b[39m=\u001b[39m raw_data\u001b[39m.\u001b[39mloc[raw_data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(vd_users)]\n\u001b[1;32m     22\u001b[0m vad_plays \u001b[39m=\u001b[39m vad_plays\u001b[39m.\u001b[39mloc[vad_plays[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(unique_sid)]\n\u001b[0;32m---> 23\u001b[0m vad_plays_tr, vad_plays_te \u001b[39m=\u001b[39m split_train_test_proportion(vad_plays)\n\u001b[1;32m     25\u001b[0m test_plays \u001b[39m=\u001b[39m raw_data\u001b[39m.\u001b[39mloc[raw_data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(te_users)]\n\u001b[1;32m     26\u001b[0m test_plays \u001b[39m=\u001b[39m test_plays\u001b[39m.\u001b[39mloc[test_plays[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(unique_sid)]\n",
            "Cell \u001b[0;32mIn[5], line 49\u001b[0m, in \u001b[0;36msplit_train_test_proportion\u001b[0;34m(data, test_prop)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         tr_list\u001b[39m.\u001b[39mappend(group)\n\u001b[0;32m---> 49\u001b[0m data_tr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(tr_list)\n\u001b[1;32m     50\u001b[0m data_te \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(te_list)\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m data_tr, data_te\n",
            "File \u001b[0;32m~/miniconda3/envs/movie/lib/python3.10/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
            "File \u001b[0;32m~/miniconda3/envs/movie/lib/python3.10/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
            "File \u001b[0;32m~/miniconda3/envs/movie/lib/python3.10/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "##훈련 데이터에 해당하는 아이템들\n",
        "#Train는 25360명만 사용\n",
        "train_plays = raw_data.loc[raw_data['user'].isin(tr_users)] # index 아닌 user 번호 기준 검색 -> unique_uid user 번호로 바꿔야 해!\n",
        "\n",
        "##아이템 ID\n",
        "unique_sid = pd.unique(train_plays['item'])\n",
        "\n",
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
        "\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)\n",
        "\n",
        "#Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n",
        "vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
        "\n",
        "test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n",
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
        "\n",
        "\n",
        "\n",
        "train_data = numerize(train_plays, profile2id, show2id)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
        "\n",
        "\n",
        "vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
        "\n",
        "vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
        "\n",
        "test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
        "\n",
        "test_data_te = numerize(test_plays_te, profile2id, show2id)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n",
        "\n",
        "inf_data = raw_data[['user','item']].copy()\n",
        "inf_data = numerize(inf_data, profile2id, show2id)\n",
        "inf_data.to_csv(os.path.join(pro_dir, 'inference.csv'), index=False)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkdg2OkjqVUM",
        "outputId": "28e101f0-e9ed-474b-8f3b-1fc161872ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 17)\t1.0\n",
            "  (0, 40)\t1.0\n",
            "  (0, 41)\t1.0\n",
            "  (0, 46)\t1.0\n",
            "  (0, 70)\t1.0\n",
            "  (0, 78)\t1.0\n",
            "  (0, 79)\t1.0\n",
            "  (0, 80)\t1.0\n",
            "  (0, 82)\t1.0\n",
            "  (0, 85)\t1.0\n",
            "  (0, 198)\t1.0\n",
            "  (0, 200)\t1.0\n",
            "  (0, 233)\t1.0\n",
            "  (0, 260)\t1.0\n",
            "  (0, 264)\t1.0\n",
            "  (0, 266)\t1.0\n",
            "  (0, 269)\t1.0\n",
            "  (0, 270)\t1.0\n",
            "  (0, 271)\t1.0\n",
            "  (0, 272)\t1.0\n",
            "  (0, 285)\t1.0\n",
            "  (0, 287)\t1.0\n",
            "  (0, 292)\t1.0\n",
            "  (0, 294)\t1.0\n",
            "  (0, 308)\t1.0\n",
            "  :\t:\n",
            "  (25359, 1429)\t1.0\n",
            "  (25359, 1447)\t1.0\n",
            "  (25359, 1794)\t1.0\n",
            "  (25359, 1872)\t1.0\n",
            "  (25359, 2436)\t1.0\n",
            "  (25359, 2669)\t1.0\n",
            "  (25359, 2776)\t1.0\n",
            "  (25359, 2777)\t1.0\n",
            "  (25359, 2860)\t1.0\n",
            "  (25359, 2882)\t1.0\n",
            "  (25359, 3041)\t1.0\n",
            "  (25359, 3063)\t1.0\n",
            "  (25359, 3101)\t1.0\n",
            "  (25359, 3247)\t1.0\n",
            "  (25359, 3340)\t1.0\n",
            "  (25359, 3886)\t1.0\n",
            "  (25359, 3956)\t1.0\n",
            "  (25359, 4293)\t1.0\n",
            "  (25359, 4328)\t1.0\n",
            "  (25359, 4492)\t1.0\n",
            "  (25359, 4606)\t1.0\n",
            "  (25359, 4915)\t1.0\n",
            "  (25359, 4946)\t1.0\n",
            "  (25359, 5026)\t1.0\n",
            "  (25359, 6637)\t1.0\n",
            "  (0, 17)\t1.0\n",
            "  (0, 46)\t1.0\n",
            "  (0, 79)\t1.0\n",
            "  (0, 82)\t1.0\n",
            "  (0, 116)\t1.0\n",
            "  (0, 149)\t1.0\n",
            "  (0, 159)\t1.0\n",
            "  (0, 196)\t1.0\n",
            "  (0, 198)\t1.0\n",
            "  (0, 207)\t1.0\n",
            "  (0, 209)\t1.0\n",
            "  (0, 260)\t1.0\n",
            "  (0, 266)\t1.0\n",
            "  (0, 270)\t1.0\n",
            "  (0, 289)\t1.0\n",
            "  (0, 292)\t1.0\n",
            "  (0, 358)\t1.0\n",
            "  (0, 362)\t1.0\n",
            "  (0, 366)\t1.0\n",
            "  (0, 375)\t1.0\n",
            "  (0, 591)\t1.0\n",
            "  (0, 639)\t1.0\n",
            "  (0, 645)\t1.0\n",
            "  (0, 718)\t1.0\n",
            "  (0, 774)\t1.0\n",
            "  :\t:\n",
            "  (2999, 833)\t1.0\n",
            "  (2999, 943)\t1.0\n",
            "  (2999, 946)\t1.0\n",
            "  (2999, 972)\t1.0\n",
            "  (2999, 993)\t1.0\n",
            "  (2999, 1040)\t1.0\n",
            "  (2999, 1050)\t1.0\n",
            "  (2999, 1062)\t1.0\n",
            "  (2999, 1144)\t1.0\n",
            "  (2999, 1158)\t1.0\n",
            "  (2999, 1235)\t1.0\n",
            "  (2999, 1248)\t1.0\n",
            "  (2999, 1287)\t1.0\n",
            "  (2999, 1302)\t1.0\n",
            "  (2999, 1338)\t1.0\n",
            "  (2999, 1398)\t1.0\n",
            "  (2999, 1504)\t1.0\n",
            "  (2999, 2003)\t1.0\n",
            "  (2999, 2165)\t1.0\n",
            "  (2999, 3378)\t1.0\n",
            "  (2999, 3406)\t1.0\n",
            "  (2999, 4199)\t1.0\n",
            "  (2999, 4536)\t1.0\n",
            "  (2999, 5275)\t1.0\n",
            "  (2999, 5503)\t1.0\n",
            "  (0, 210)\t1.0\n",
            "  (0, 560)\t1.0\n",
            "  (0, 685)\t1.0\n",
            "  (0, 690)\t1.0\n",
            "  (0, 711)\t1.0\n",
            "  (0, 935)\t1.0\n",
            "  (0, 1040)\t1.0\n",
            "  (0, 1154)\t1.0\n",
            "  (0, 3123)\t1.0\n",
            "  (1, 86)\t1.0\n",
            "  (1, 116)\t1.0\n",
            "  (1, 148)\t1.0\n",
            "  (1, 159)\t1.0\n",
            "  (1, 186)\t1.0\n",
            "  (1, 207)\t1.0\n",
            "  (1, 264)\t1.0\n",
            "  (1, 270)\t1.0\n",
            "  (1, 283)\t1.0\n",
            "  (1, 292)\t1.0\n",
            "  (1, 300)\t1.0\n",
            "  (1, 306)\t1.0\n",
            "  (1, 359)\t1.0\n",
            "  (1, 482)\t1.0\n",
            "  (1, 632)\t1.0\n",
            "  (1, 1526)\t1.0\n",
            "  :\t:\n",
            "  (2997, 853)\t1.0\n",
            "  (2997, 1150)\t1.0\n",
            "  (2997, 1451)\t1.0\n",
            "  (2998, 41)\t1.0\n",
            "  (2998, 82)\t1.0\n",
            "  (2998, 144)\t1.0\n",
            "  (2998, 265)\t1.0\n",
            "  (2998, 362)\t1.0\n",
            "  (2998, 566)\t1.0\n",
            "  (2998, 782)\t1.0\n",
            "  (2998, 1016)\t1.0\n",
            "  (2998, 1916)\t1.0\n",
            "  (2998, 2212)\t1.0\n",
            "  (2999, 277)\t1.0\n",
            "  (2999, 312)\t1.0\n",
            "  (2999, 462)\t1.0\n",
            "  (2999, 483)\t1.0\n",
            "  (2999, 662)\t1.0\n",
            "  (2999, 810)\t1.0\n",
            "  (2999, 952)\t1.0\n",
            "  (2999, 1015)\t1.0\n",
            "  (2999, 1369)\t1.0\n",
            "  (2999, 2175)\t1.0\n",
            "  (2999, 2188)\t1.0\n",
            "  (2999, 3380)\t1.0\n"
          ]
        }
      ],
      "source": [
        "#데이터 셋 확인\n",
        "print(train_data)\n",
        "print(vad_data_tr)\n",
        "print(vad_data_te)\n",
        "# print(test_data_tr)\n",
        "# print(test_data_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMiq9leyWWL1"
      },
      "source": [
        "##3. 데이터 로더 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "nxUADr9ibxa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataLoader(): # 존재하지도 않는 user가 sparse matrix 상에 포함됨\n",
        "    '''\n",
        "    Load Movielens dataset\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "\n",
        "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
        "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
        "\n",
        "        self.n_items = self.load_n_items()\n",
        "\n",
        "    def load_data(self, datatype='train'):\n",
        "        if datatype == 'train':\n",
        "            return self._load_train_data()\n",
        "        elif datatype == 'validation':\n",
        "            return self._load_tr_te_data(datatype)\n",
        "        elif datatype == 'test':\n",
        "            return self._load_tr_te_data(datatype)\n",
        "        elif datatype == 'inference':\n",
        "            return self._load_inf_data(datatype)\n",
        "        else:\n",
        "            raise ValueError(\"datatype should be in [train, validation, test, inference]\")\n",
        "\n",
        "    def load_n_items(self):\n",
        "        unique_sid = list()\n",
        "        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "            for line in f:\n",
        "                unique_sid.append(line.strip())\n",
        "        n_items = len(unique_sid)\n",
        "        return n_items\n",
        "\n",
        "    def _load_train_data(self):\n",
        "        path = os.path.join(self.pro_dir, 'train.csv')\n",
        "\n",
        "        tp = pd.read_csv(path)\n",
        "        n_users = tp['uid'].max() + 1\n",
        "\n",
        "        rows, cols = tp['uid'], tp['sid']\n",
        "        data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                                 (rows, cols)), dtype='float64',\n",
        "                                 shape=(n_users, self.n_items)) # uid,sid에만 1 채우고 나머지는 모두 0을 채우는 sparse interaction matrix\n",
        "        return data\n",
        "\n",
        "    def _load_tr_te_data(self, datatype='test'):\n",
        "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
        "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
        "\n",
        "        tp_tr = pd.read_csv(tr_path)\n",
        "        tp_te = pd.read_csv(te_path)\n",
        "\n",
        "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
        "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
        "        \n",
        "        return data_tr, data_te\n",
        "    \n",
        "    def _load_inf_data(self, datatype='inference'):\n",
        "        inf_path = os.path.join(self.pro_dir, 'inference.csv')\n",
        "\n",
        "        data_inf = pd.read_csv(inf_path)\n",
        "\n",
        "        n_rows = data_inf.uid.nunique()\n",
        "        n_cols = data_inf.sid.nunique()\n",
        "\n",
        "        rows = data_inf['uid']\n",
        "        cols = data_inf['sid']\n",
        "\n",
        "        data_inf = sparse.csr_matrix((np.ones_like(rows),\n",
        "                                    (rows, cols)), dtype='float64', shape=(n_rows, n_cols))\n",
        "\n",
        "        return data_inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHhwKqXWaUZ"
      },
      "source": [
        "## 4. 모델정의\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "id": "QYlGPJTYU0ii"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#이미 완성된 MultiDAE의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n",
        "class MultiDAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Container module for Multi-DAE.\n",
        "\n",
        "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
        "    See Variational Autoencoders for Collaborative Filtering\n",
        "    https://arxiv.org/abs/1802.05814\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
        "        super(MultiDAE, self).__init__()\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims:\n",
        "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        else:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # h = F.normalize(input)\n",
        "        h = self.drop(input)\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "\n",
        "\n",
        "class MultiVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Container module for Multi-VAE.\n",
        "\n",
        "    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n",
        "    See Variational Autoencoders for Collaborative Filtering\n",
        "    https://arxiv.org/abs/1802.05814\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
        "        super(MultiVAE, self).__init__()\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims:\n",
        "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        else:\n",
        "            self.q_dims = p_dims[::-1] # default: 대칭 구조\n",
        "\n",
        "        # Last dimension of q- network is for mean and variance\n",
        "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
        "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
        "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input):\n",
        "        mu, logvar = self.encode(input)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "    def encode(self, input):\n",
        "        # h = F.normalize(input)\n",
        "        h = self.drop(input)\n",
        "\n",
        "        for i, layer in enumerate(self.q_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.q_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "            else: #\n",
        "                mu = h[:, :self.q_dims[-1]]\n",
        "                logvar = h[:, self.q_dims[-1]:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar): # latent factor(모수) 조정\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std) # std와 동일 모양의 N(0,1)난수생성\n",
        "            return eps.mul(std).add_(mu) # train: 난수*std + mu\n",
        "        else:\n",
        "            return mu # val/test: mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = z\n",
        "        for i, layer in enumerate(self.p_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.p_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.q_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "        for layer in self.p_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
        "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1)) # softmax: multinomial의 loss\n",
        "    # BCE = torch.nn.BCEWithLogitsLoss(reduction='sum')(recon_x, x)\n",
        "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)) # \n",
        "\n",
        "    return BCE + anneal * KLD\n",
        "\n",
        "def loss_function_dae(recon_x, x):\n",
        "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
        "    # BCE = torch.nn.BCEWithLogitsLoss(reduction='sum')(recon_x, x)\n",
        "    return BCE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "7nEfVTktbxa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sparse2torch_sparse(data): # encoder F.normalize에서 대신 활용\n",
        "    \"\"\"\n",
        "    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n",
        "    This is much faster than naive use of torch.FloatTensor(data.toarray())\n",
        "    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n",
        "    \"\"\"\n",
        "    samples = data.shape[0] # n_users\n",
        "    features = data.shape[1] # n_items\n",
        "    coo_data = data.tocoo()\n",
        "    indices = torch.LongTensor([coo_data.row, coo_data.col])\n",
        "    row_norms_inv = 1 / np.sqrt(data.sum(1)) # 유저별로 interaction 수만큼 normalize\n",
        "    # row_norms_inv = 1 / np.linalg.norm(data, axis=1) # 유저별로 interaction 수만큼 normalize\n",
        "    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n",
        "    values = np.array([row2val[r] for r in coo_data.row])\n",
        "    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n",
        "    return torch.FloatTensor(t.to_dense())\n",
        "\n",
        "def naive_sparse2tensor(data):\n",
        "    return torch.FloatTensor(data.toarray())\n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer, is_VAE = False):\n",
        "    # Turn on training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    global update_count\n",
        "\n",
        "    np.random.shuffle(idxlist)\n",
        "\n",
        "    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n",
        "        end_idx = min(start_idx + args.batch_size, N)\n",
        "        data = train_data[idxlist[start_idx:end_idx]] # 여기의 train_data: sparse interaction matrix 형태\n",
        "        data = naive_sparse2tensor(data).to(device)\n",
        "        # data = sparse2torch_sparse(data).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if is_VAE:\n",
        "          if args.total_anneal_steps > 0:\n",
        "            anneal = min(args.anneal_cap,\n",
        "                            1. * update_count / args.total_anneal_steps)\n",
        "          else:\n",
        "              anneal = args.anneal_cap\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          recon_batch, mu, logvar = model(data)\n",
        "\n",
        "          loss = criterion(recon_batch, data, mu, logvar, anneal)\n",
        "        else:\n",
        "          recon_batch = model(data)\n",
        "          loss = criterion(recon_batch, data)\n",
        "\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        update_count += 1\n",
        "\n",
        "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
        "                    'loss {:4.2f}'.format(\n",
        "                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n",
        "                        elapsed * 1000 / args.log_interval,\n",
        "                        train_loss / args.log_interval))\n",
        "\n",
        "\n",
        "            start_time = time.time()\n",
        "            train_loss = 0.0\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n",
        "    # Turn on evaluation mode\n",
        "    model.eval()\n",
        "    global update_count\n",
        "    e_idxlist = list(range(data_tr.shape[0]))\n",
        "    e_N = data_tr.shape[0]\n",
        "    total_val_loss_list = []\n",
        "    n100_list = []\n",
        "    r20_list = []\n",
        "    r50_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, e_N, args.batch_size):\n",
        "            end_idx = min(start_idx + args.batch_size, N)\n",
        "            data = data_tr[e_idxlist[start_idx:end_idx]]\n",
        "            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n",
        "\n",
        "            data_tensor = naive_sparse2tensor(data).to(device)\n",
        "            # data_tensor = sparse2torch_sparse(data).to(device)\n",
        "            if is_VAE :\n",
        "\n",
        "              if args.total_anneal_steps > 0:\n",
        "                  anneal = min(args.anneal_cap,\n",
        "                                1. * update_count / args.total_anneal_steps)\n",
        "              else:\n",
        "                  anneal = args.anneal_cap\n",
        "\n",
        "              recon_batch, mu, logvar = model(data_tensor)\n",
        "\n",
        "              loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n",
        "\n",
        "            else :\n",
        "              recon_batch = model(data_tensor)\n",
        "              loss = criterion(recon_batch, data_tensor)\n",
        "\n",
        "            total_val_loss_list.append(loss.item())\n",
        "\n",
        "            # Exclude examples from training set\n",
        "            recon_batch = recon_batch.cpu().numpy()\n",
        "            recon_batch[data.nonzero()] = -np.inf\n",
        "\n",
        "            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n",
        "            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n",
        "            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n",
        "            # top10 = torch.topk(recon_batch)\n",
        "\n",
        "            n100_list.append(n100)\n",
        "            r20_list.append(r20)\n",
        "            r50_list.append(r50)\n",
        "\n",
        "    n100_list = np.concatenate(n100_list)\n",
        "    r20_list = np.concatenate(r20_list)\n",
        "    r50_list = np.concatenate(r50_list)\n",
        "\n",
        "    return np.nanmean(total_val_loss_list), np.nanmean(n100_list), np.nanmean(r20_list), np.nanmean(r50_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOsCJbb_X9gl"
      },
      "source": [
        "## Metric 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "zxNtit6vbxa-"
      },
      "outputs": [],
      "source": [
        "import bottleneck as bn\n",
        "import numpy as np\n",
        "\n",
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    Normalized Discounted Cumulative Gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG\n",
        "\n",
        "\n",
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDD7lD7sHcnH"
      },
      "source": [
        "## MultiDAE 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "WLYyTwToX4fm"
      },
      "outputs": [],
      "source": [
        "\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "n_items = loader.load_n_items()\n",
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader.load_data('test')\n",
        "\n",
        "N = train_data.shape[0]\n",
        "idxlist = list(range(N))\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "p_dims = [200, 600, n_items]\n",
        "model = MultiDAE(p_dims).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
        "criterion = loss_function_dae\n",
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "best_n100 = -np.inf\n",
        "update_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rOEDs2Lbxa-",
        "outputId": "ccbcf453-8276-498e-85d8-f44a83687c6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1.66s | valid loss 259683.58 | n100 0.262 | r20 0.192 | r50 0.238\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1.50s | valid loss 253584.77 | n100 0.262 | r20 0.191 | r50 0.238\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1.53s | valid loss 236254.58 | n100 0.263 | r20 0.193 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1.53s | valid loss 231153.55 | n100 0.264 | r20 0.191 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1.62s | valid loss 229580.88 | n100 0.264 | r20 0.194 | r50 0.241\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1.60s | valid loss 224403.30 | n100 0.274 | r20 0.202 | r50 0.251\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1.61s | valid loss 222482.88 | n100 0.280 | r20 0.207 | r50 0.257\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1.56s | valid loss 216268.48 | n100 0.304 | r20 0.229 | r50 0.278\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1.56s | valid loss 212178.99 | n100 0.311 | r20 0.234 | r50 0.285\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1.64s | valid loss 208338.39 | n100 0.324 | r20 0.244 | r50 0.297\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1.63s | valid loss 205906.56 | n100 0.330 | r20 0.247 | r50 0.301\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1.65s | valid loss 204463.88 | n100 0.334 | r20 0.251 | r50 0.306\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1.62s | valid loss 202732.46 | n100 0.339 | r20 0.255 | r50 0.310\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1.62s | valid loss 202766.08 | n100 0.342 | r20 0.258 | r50 0.314\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1.63s | valid loss 198696.98 | n100 0.349 | r20 0.263 | r50 0.319\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1.62s | valid loss 196021.28 | n100 0.359 | r20 0.273 | r50 0.329\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1.68s | valid loss 194700.95 | n100 0.366 | r20 0.279 | r50 0.334\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1.68s | valid loss 193072.54 | n100 0.371 | r20 0.282 | r50 0.339\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1.62s | valid loss 192554.23 | n100 0.374 | r20 0.285 | r50 0.342\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1.65s | valid loss 190882.79 | n100 0.378 | r20 0.288 | r50 0.345\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1.64s | valid loss 190004.75 | n100 0.382 | r20 0.292 | r50 0.350\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1.65s | valid loss 188671.34 | n100 0.388 | r20 0.297 | r50 0.355\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1.66s | valid loss 187192.39 | n100 0.390 | r20 0.299 | r50 0.357\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1.65s | valid loss 186746.80 | n100 0.391 | r20 0.299 | r50 0.358\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1.74s | valid loss 186610.84 | n100 0.395 | r20 0.302 | r50 0.360\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 1.68s | valid loss 185055.19 | n100 0.396 | r20 0.303 | r50 0.363\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 1.59s | valid loss 183851.92 | n100 0.400 | r20 0.307 | r50 0.367\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 1.63s | valid loss 184604.08 | n100 0.401 | r20 0.307 | r50 0.369\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 1.58s | valid loss 183167.09 | n100 0.403 | r20 0.308 | r50 0.369\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 1.71s | valid loss 182759.10 | n100 0.407 | r20 0.312 | r50 0.373\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 1.64s | valid loss 182004.63 | n100 0.408 | r20 0.314 | r50 0.373\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 1.63s | valid loss 181693.41 | n100 0.408 | r20 0.315 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 1.73s | valid loss 180374.49 | n100 0.411 | r20 0.317 | r50 0.377\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 1.63s | valid loss 179890.89 | n100 0.412 | r20 0.317 | r50 0.378\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 1.65s | valid loss 180018.95 | n100 0.415 | r20 0.320 | r50 0.380\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 1.59s | valid loss 178838.96 | n100 0.417 | r20 0.323 | r50 0.381\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 1.64s | valid loss 179175.21 | n100 0.418 | r20 0.325 | r50 0.382\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 1.63s | valid loss 179060.30 | n100 0.420 | r20 0.324 | r50 0.383\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 1.67s | valid loss 179133.11 | n100 0.422 | r20 0.327 | r50 0.385\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 1.66s | valid loss 177047.12 | n100 0.423 | r20 0.327 | r50 0.386\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 1.61s | valid loss 177813.74 | n100 0.426 | r20 0.331 | r50 0.388\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 1.70s | valid loss 176721.97 | n100 0.427 | r20 0.331 | r50 0.389\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 1.72s | valid loss 175898.08 | n100 0.427 | r20 0.331 | r50 0.389\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 1.74s | valid loss 175241.71 | n100 0.428 | r20 0.331 | r50 0.390\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 1.59s | valid loss 174903.49 | n100 0.428 | r20 0.332 | r50 0.390\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 1.59s | valid loss 174809.21 | n100 0.429 | r20 0.333 | r50 0.391\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 1.67s | valid loss 174592.35 | n100 0.431 | r20 0.333 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 1.74s | valid loss 173711.42 | n100 0.431 | r20 0.334 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 1.71s | valid loss 174802.64 | n100 0.432 | r20 0.334 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 1.65s | valid loss 174309.80 | n100 0.432 | r20 0.336 | r50 0.394\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 1.62s | valid loss 173718.97 | n100 0.433 | r20 0.336 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 1.60s | valid loss 174163.81 | n100 0.434 | r20 0.337 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 1.63s | valid loss 172252.99 | n100 0.435 | r20 0.337 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 1.70s | valid loss 172633.96 | n100 0.434 | r20 0.336 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 1.71s | valid loss 174462.39 | n100 0.435 | r20 0.337 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 1.63s | valid loss 173156.63 | n100 0.438 | r20 0.340 | r50 0.398\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 1.64s | valid loss 172578.28 | n100 0.436 | r20 0.340 | r50 0.399\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 1.59s | valid loss 172582.96 | n100 0.438 | r20 0.340 | r50 0.399\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 1.66s | valid loss 171257.50 | n100 0.437 | r20 0.339 | r50 0.400\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 168874.17 | n100 0.44 | r20 0.34 | r50 0.40\n",
            "=========================================================================================\n",
            "best epoch: 58\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, args.epochs+40):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, criterion, optimizer, is_VAE=False)\n",
        "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "\n",
        "\n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_n100:\n",
        "        with open(args.save, 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_n100 = n100\n",
        "        best_epoch = epoch\n",
        "\n",
        "\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
        "print('=' * 89)\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1QjCbMBXw4v"
      },
      "source": [
        "## MultiVAE 테스트 (TODO)\n",
        "\n",
        "위의 MultiVAE 모델 코드, train, evaluate 함수를 완성하여, 아래 훈련 코드가 정상적으로 동작하도록 해보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "78zFFNzgbxa_"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "n_items = loader.load_n_items()\n",
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader.load_data('test')\n",
        "\n",
        "N = train_data.shape[0] # n_users\n",
        "idxlist = list(range(N)) # 유저들 묶음을 batch로\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "p_dims = [200, 600, n_items]\n",
        "model = MultiVAE(p_dims).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n",
        "criterion = loss_function_vae\n",
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "best_n100 = -np.inf\n",
        "update_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoUFwndCvvtp",
        "outputId": "3ec0ad84-6ac1-43f7-9ad1-8de61e1307d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1.68s | valid loss 257870.44 | n100 0.259 | r20 0.191 | r50 0.236\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1.57s | valid loss 244882.44 | n100 0.262 | r20 0.189 | r50 0.238\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1.61s | valid loss 237222.62 | n100 0.260 | r20 0.190 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1.55s | valid loss 234359.27 | n100 0.263 | r20 0.190 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1.66s | valid loss 232969.33 | n100 0.263 | r20 0.192 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1.62s | valid loss 231792.95 | n100 0.262 | r20 0.193 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1.60s | valid loss 229369.92 | n100 0.264 | r20 0.195 | r50 0.241\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1.57s | valid loss 227265.66 | n100 0.270 | r20 0.201 | r50 0.248\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1.51s | valid loss 226283.13 | n100 0.273 | r20 0.201 | r50 0.250\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1.57s | valid loss 224913.71 | n100 0.277 | r20 0.204 | r50 0.253\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1.67s | valid loss 223438.55 | n100 0.279 | r20 0.206 | r50 0.257\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1.65s | valid loss 220578.03 | n100 0.293 | r20 0.218 | r50 0.267\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1.63s | valid loss 218455.54 | n100 0.301 | r20 0.226 | r50 0.275\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1.71s | valid loss 215390.25 | n100 0.308 | r20 0.231 | r50 0.282\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1.58s | valid loss 213192.98 | n100 0.314 | r20 0.235 | r50 0.288\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1.55s | valid loss 211420.12 | n100 0.318 | r20 0.240 | r50 0.290\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1.62s | valid loss 209936.40 | n100 0.323 | r20 0.241 | r50 0.294\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1.79s | valid loss 209086.19 | n100 0.327 | r20 0.244 | r50 0.298\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1.57s | valid loss 207423.29 | n100 0.332 | r20 0.252 | r50 0.303\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1.67s | valid loss 207235.53 | n100 0.335 | r20 0.254 | r50 0.305\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1.62s | valid loss 205082.08 | n100 0.339 | r20 0.256 | r50 0.309\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1.63s | valid loss 205103.15 | n100 0.340 | r20 0.257 | r50 0.311\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1.66s | valid loss 203284.01 | n100 0.345 | r20 0.261 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1.74s | valid loss 202348.43 | n100 0.347 | r20 0.263 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1.71s | valid loss 201565.87 | n100 0.349 | r20 0.266 | r50 0.320\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 1.58s | valid loss 200390.85 | n100 0.354 | r20 0.270 | r50 0.324\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 1.66s | valid loss 199629.22 | n100 0.356 | r20 0.271 | r50 0.324\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 1.73s | valid loss 199495.28 | n100 0.361 | r20 0.276 | r50 0.330\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 1.64s | valid loss 199266.15 | n100 0.362 | r20 0.274 | r50 0.330\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 1.57s | valid loss 197276.33 | n100 0.364 | r20 0.277 | r50 0.332\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 1.58s | valid loss 196141.80 | n100 0.366 | r20 0.277 | r50 0.334\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 1.49s | valid loss 195886.70 | n100 0.372 | r20 0.283 | r50 0.338\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 1.60s | valid loss 194509.86 | n100 0.372 | r20 0.283 | r50 0.338\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 1.61s | valid loss 194415.50 | n100 0.375 | r20 0.284 | r50 0.340\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 1.57s | valid loss 193393.41 | n100 0.379 | r20 0.288 | r50 0.346\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 1.67s | valid loss 192620.80 | n100 0.382 | r20 0.292 | r50 0.348\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 1.54s | valid loss 190974.59 | n100 0.384 | r20 0.294 | r50 0.352\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 1.69s | valid loss 190578.31 | n100 0.387 | r20 0.297 | r50 0.355\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 1.65s | valid loss 189690.88 | n100 0.388 | r20 0.298 | r50 0.356\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 1.72s | valid loss 188485.09 | n100 0.392 | r20 0.301 | r50 0.359\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 1.72s | valid loss 188613.91 | n100 0.395 | r20 0.303 | r50 0.361\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 1.64s | valid loss 187533.64 | n100 0.395 | r20 0.304 | r50 0.362\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 1.69s | valid loss 187454.25 | n100 0.400 | r20 0.308 | r50 0.366\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 1.70s | valid loss 185102.73 | n100 0.402 | r20 0.310 | r50 0.368\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 1.59s | valid loss 184462.29 | n100 0.404 | r20 0.312 | r50 0.370\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 1.61s | valid loss 183196.74 | n100 0.408 | r20 0.313 | r50 0.374\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 1.64s | valid loss 182096.70 | n100 0.410 | r20 0.316 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 1.78s | valid loss 182216.62 | n100 0.412 | r20 0.318 | r50 0.376\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 1.73s | valid loss 180448.68 | n100 0.415 | r20 0.321 | r50 0.379\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 1.73s | valid loss 179923.16 | n100 0.418 | r20 0.323 | r50 0.381\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 1.68s | valid loss 178872.23 | n100 0.420 | r20 0.325 | r50 0.385\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 1.64s | valid loss 178255.58 | n100 0.424 | r20 0.329 | r50 0.388\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 1.73s | valid loss 176128.51 | n100 0.426 | r20 0.331 | r50 0.388\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 1.66s | valid loss 175767.60 | n100 0.429 | r20 0.332 | r50 0.392\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 1.62s | valid loss 174218.63 | n100 0.432 | r20 0.336 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 1.58s | valid loss 174354.38 | n100 0.434 | r20 0.339 | r50 0.397\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 1.59s | valid loss 173144.85 | n100 0.437 | r20 0.341 | r50 0.401\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 1.67s | valid loss 171819.12 | n100 0.440 | r20 0.343 | r50 0.402\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 1.71s | valid loss 169900.47 | n100 0.441 | r20 0.344 | r50 0.403\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 166396.17 | n100 0.44 | r20 0.34 | r50 0.41\n",
            "=========================================================================================\n",
            "best epoch: 59\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, args.epochs + 40):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, criterion, optimizer, is_VAE=True)\n",
        "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "\n",
        "\n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_n100:\n",
        "        with open(args.save, 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_n100 = n100\n",
        "        best_epoch = epoch\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
        "print('=' * 89)\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xBh0Mrcn6Af"
      },
      "source": [
        "## Required Package\n",
        "\n",
        "- numpy==1.23.5\n",
        "- pandas==1.5.3\n",
        "- torch==2.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQjnnLZ-Jf5b"
      },
      "source": [
        "###**콘텐츠 라이선스**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference\n",
        "\n",
        "전체 학습 -> inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_N = raw_data.user.nunique()\n",
        "idx_list = np.arange(total_N)\n",
        "\n",
        "id2show = {v:k for k,v in show2id.items()}\n",
        "id2profile = {v:k for k,v in profile2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'model_total.pt'"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "args.save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inference(model, criterion, data, is_VAE=False):\n",
        "   \n",
        "# Load the best saved model.\n",
        "    with open(args.save, 'rb') as f:\n",
        "      model = torch.load(f)\n",
        "    \n",
        "    # turn on eval mode\n",
        "    model.eval()\n",
        "    global update_count\n",
        "    idxlist = list(range(data.shape[0]))\n",
        "    N = data.shape[0]\n",
        "    total_topk = []\n",
        "    result = pd.DataFrame()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, N, args.batch_size):\n",
        "            end_idx = min(start_idx + args.batch_size, N)\n",
        "            batch = data[idxlist[start_idx:end_idx]]\n",
        "\n",
        "            # data_tensor = naive_sparse2tensor(data).to(device)\n",
        "            data_tensor = sparse2torch_sparse(batch).to(device)\n",
        "            if is_VAE :\n",
        "\n",
        "              if args.total_anneal_steps > 0:\n",
        "                  anneal = min(args.anneal_cap,\n",
        "                                1. * update_count / args.total_anneal_steps)\n",
        "              else:\n",
        "                  anneal = args.anneal_cap\n",
        "\n",
        "              recon_batch, mu, logvar = model(data_tensor)\n",
        "\n",
        "            else :\n",
        "              recon_batch = model(data_tensor)\n",
        "\n",
        "            # Exclude examples from training set\n",
        "            recon_batch[batch.nonzero()] = -1e9\n",
        "\n",
        "            topk = torch.topk(input=recon_batch, k=10)\n",
        "            batch_topk = list(topk.indices.reshape(-1).detach().cpu().numpy())\n",
        "          \n",
        "            total_topk.extend(batch_topk)\n",
        "\n",
        "\n",
        "    result['user'] = np.repeat(np.arange(31360),10)\n",
        "    result['item'] = total_topk\n",
        "\n",
        "    result['user'] = result['user'].apply(lambda x: id2profile[x])\n",
        "    result['item'] = result['item'].apply(lambda x: id2show[x])\n",
        "    \n",
        "    return result.sort_values('user').reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrain(model, criterion, optimizer, train_data=data_inf, is_VAE = False):\n",
        "    # Turn on training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    global update_count\n",
        "    N = train_data.shape[0]\n",
        "    idxlist = np.arange(N)\n",
        "\n",
        "    np.random.shuffle(idxlist)\n",
        "\n",
        "    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n",
        "        end_idx = min(start_idx + args.batch_size, N)\n",
        "        batch = train_data[idxlist[start_idx:end_idx]] # 여기의 train_data: sparse interaction matrix 형태\n",
        "        data = naive_sparse2tensor(batch).to(device)\n",
        "        # data = sparse2torch_sparse(batch).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if is_VAE:\n",
        "          if args.total_anneal_steps > 0:\n",
        "            anneal = min(args.anneal_cap,\n",
        "                            1. * update_count / args.total_anneal_steps)\n",
        "          else:\n",
        "              anneal = args.anneal_cap\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          recon_batch, mu, logvar = model(data)\n",
        "\n",
        "          loss = criterion(recon_batch, data, mu, logvar, anneal)\n",
        "        else:\n",
        "          recon_batch = model(data)\n",
        "          loss = criterion(recon_batch, data)\n",
        "\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        update_count += 1\n",
        "\n",
        "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
        "                    'loss {:4.2f}'.format(\n",
        "                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n",
        "                        elapsed * 1000 / args.log_interval,\n",
        "                        train_loss / args.log_interval))\n",
        "\n",
        "\n",
        "            start_time = time.time()\n",
        "            train_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_dims = [200, 600, n_items]\n",
        "model = MultiVAE(p_dims).to(device)\n",
        "loader = DataLoader(args.data)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n",
        "criterion = loss_function_vae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1.62s | valid loss 257006.02 | n100 0.261 | r20 0.191 | r50 0.236\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1.56s | valid loss 241311.42 | n100 0.263 | r20 0.191 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1.49s | valid loss 235747.03 | n100 0.262 | r20 0.190 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1.51s | valid loss 233817.99 | n100 0.263 | r20 0.192 | r50 0.240\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1.53s | valid loss 232515.37 | n100 0.263 | r20 0.191 | r50 0.239\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1.59s | valid loss 230377.44 | n100 0.266 | r20 0.194 | r50 0.241\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1.65s | valid loss 228247.84 | n100 0.270 | r20 0.199 | r50 0.246\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1.48s | valid loss 226076.11 | n100 0.272 | r20 0.202 | r50 0.250\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1.59s | valid loss 224181.16 | n100 0.277 | r20 0.203 | r50 0.253\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1.55s | valid loss 222173.60 | n100 0.284 | r20 0.209 | r50 0.261\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1.52s | valid loss 218874.01 | n100 0.299 | r20 0.225 | r50 0.275\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1.67s | valid loss 214986.12 | n100 0.313 | r20 0.236 | r50 0.287\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1.62s | valid loss 212032.61 | n100 0.322 | r20 0.242 | r50 0.294\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1.58s | valid loss 209220.15 | n100 0.326 | r20 0.247 | r50 0.299\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1.63s | valid loss 208625.19 | n100 0.331 | r20 0.249 | r50 0.303\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 1.54s | valid loss 206837.45 | n100 0.335 | r20 0.253 | r50 0.305\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 1.70s | valid loss 205307.43 | n100 0.338 | r20 0.255 | r50 0.309\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 1.73s | valid loss 203582.67 | n100 0.344 | r20 0.259 | r50 0.312\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 1.68s | valid loss 202094.72 | n100 0.346 | r20 0.260 | r50 0.316\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 1.64s | valid loss 201125.92 | n100 0.352 | r20 0.267 | r50 0.322\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 1.58s | valid loss 200763.41 | n100 0.356 | r20 0.269 | r50 0.324\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 1.64s | valid loss 198083.63 | n100 0.361 | r20 0.274 | r50 0.329\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 1.62s | valid loss 197762.70 | n100 0.364 | r20 0.275 | r50 0.334\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 1.64s | valid loss 195684.05 | n100 0.367 | r20 0.279 | r50 0.335\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 1.67s | valid loss 195286.76 | n100 0.369 | r20 0.280 | r50 0.338\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 1.57s | valid loss 194224.64 | n100 0.371 | r20 0.283 | r50 0.339\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 1.69s | valid loss 194096.60 | n100 0.374 | r20 0.285 | r50 0.341\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 1.64s | valid loss 193755.89 | n100 0.374 | r20 0.285 | r50 0.342\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 1.68s | valid loss 192048.51 | n100 0.378 | r20 0.288 | r50 0.345\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 1.65s | valid loss 191538.78 | n100 0.380 | r20 0.291 | r50 0.348\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 1.60s | valid loss 190422.60 | n100 0.384 | r20 0.293 | r50 0.351\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 1.69s | valid loss 189737.52 | n100 0.386 | r20 0.295 | r50 0.352\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 1.64s | valid loss 189581.29 | n100 0.388 | r20 0.297 | r50 0.355\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 1.69s | valid loss 188167.28 | n100 0.391 | r20 0.301 | r50 0.357\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 1.67s | valid loss 187711.42 | n100 0.395 | r20 0.302 | r50 0.360\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 1.64s | valid loss 185742.16 | n100 0.397 | r20 0.305 | r50 0.365\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 1.64s | valid loss 185476.23 | n100 0.402 | r20 0.308 | r50 0.368\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 1.60s | valid loss 183350.55 | n100 0.404 | r20 0.312 | r50 0.371\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 1.66s | valid loss 182391.61 | n100 0.407 | r20 0.312 | r50 0.374\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 1.58s | valid loss 182151.28 | n100 0.411 | r20 0.316 | r50 0.375\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 1.59s | valid loss 181296.33 | n100 0.414 | r20 0.320 | r50 0.379\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 1.65s | valid loss 178762.14 | n100 0.418 | r20 0.323 | r50 0.382\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 1.62s | valid loss 178244.50 | n100 0.421 | r20 0.326 | r50 0.387\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 1.73s | valid loss 177284.66 | n100 0.425 | r20 0.328 | r50 0.389\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 1.61s | valid loss 175915.60 | n100 0.428 | r20 0.334 | r50 0.391\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 1.68s | valid loss 175697.83 | n100 0.430 | r20 0.336 | r50 0.393\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 1.64s | valid loss 174141.16 | n100 0.435 | r20 0.339 | r50 0.395\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 1.64s | valid loss 172049.71 | n100 0.436 | r20 0.341 | r50 0.398\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 1.69s | valid loss 171542.51 | n100 0.439 | r20 0.343 | r50 0.400\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 1.66s | valid loss 170064.88 | n100 0.441 | r20 0.345 | r50 0.403\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 1.64s | valid loss 169622.47 | n100 0.443 | r20 0.346 | r50 0.404\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 1.71s | valid loss 169119.76 | n100 0.443 | r20 0.347 | r50 0.405\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 1.59s | valid loss 167051.82 | n100 0.447 | r20 0.349 | r50 0.408\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 1.68s | valid loss 166551.84 | n100 0.448 | r20 0.351 | r50 0.409\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 1.57s | valid loss 165562.39 | n100 0.448 | r20 0.352 | r50 0.411\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 1.72s | valid loss 165819.22 | n100 0.451 | r20 0.354 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 1.64s | valid loss 164835.88 | n100 0.452 | r20 0.356 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 1.60s | valid loss 162825.06 | n100 0.452 | r20 0.356 | r50 0.412\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 1.71s | valid loss 161969.43 | n100 0.453 | r20 0.356 | r50 0.413\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 158710.63 | n100 0.45 | r20 0.35 | r50 0.42\n",
            "=========================================================================================\n",
            "best epoch: 59\n"
          ]
        }
      ],
      "source": [
        "train_data = loader.load_data('train')\n",
        "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
        "test_data_tr, test_data_te = loader._load_tr_te_data('test')\n",
        "data_inf = loader.load_data('inference')\n",
        "\n",
        "N = train_data.shape[0]\n",
        "idx_list = np.arange(N)\n",
        "\n",
        "best_n100 = -np.inf\n",
        "for epoch in range(1, args.epochs + 40):\n",
        "    epoch_start_time = time.time()\n",
        "    # retrain(model, criterion, optimizer, data_inf, is_VAE=True)\n",
        "    train(model, criterion, optimizer, is_VAE=True)\n",
        "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
        "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
        "                epoch, time.time() - epoch_start_time, val_loss,\n",
        "                n100, r20, r50))\n",
        "    print('-' * 89)\n",
        "\n",
        "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
        "\n",
        "\n",
        "    # Save the model if the n100 is the best we've seen so far.\n",
        "    if n100 > best_n100:\n",
        "        with open('model_total.pt', 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_n100 = n100\n",
        "        best_epoch=epoch\n",
        "\n",
        "\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "\n",
        "# Run on test data.\n",
        "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
        "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
        "print('=' * 89)\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/ml/miniconda3/envs/movie/lib/python3.10/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        }
      ],
      "source": [
        "args.save='model_total.pt'\n",
        "result = inference(model, criterion, data_inf, is_VAE=True)\n",
        "result.to_csv('multi-vae.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>2329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>72998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>32587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>34405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313595</th>\n",
              "      <td>138493</td>\n",
              "      <td>8961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313596</th>\n",
              "      <td>138493</td>\n",
              "      <td>1270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313597</th>\n",
              "      <td>138493</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313598</th>\n",
              "      <td>138493</td>\n",
              "      <td>32587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313599</th>\n",
              "      <td>138493</td>\n",
              "      <td>4995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>313600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user   item\n",
              "0           11   2329\n",
              "1           11  72998\n",
              "2           11  32587\n",
              "3           11  34405\n",
              "4           11   4370\n",
              "...        ...    ...\n",
              "313595  138493   8961\n",
              "313596  138493   1270\n",
              "313597  138493   2012\n",
              "313598  138493  32587\n",
              "313599  138493   4995\n",
              "\n",
              "[313600 rows x 2 columns]"
            ]
          },
          "execution_count": 408,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>5218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>8861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>3986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>2054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313595</th>\n",
              "      <td>138493</td>\n",
              "      <td>4370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313596</th>\n",
              "      <td>138493</td>\n",
              "      <td>589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313597</th>\n",
              "      <td>138493</td>\n",
              "      <td>2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313598</th>\n",
              "      <td>138493</td>\n",
              "      <td>33615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313599</th>\n",
              "      <td>138493</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>313600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user   item\n",
              "0           11   5218\n",
              "1           11   8861\n",
              "2           11   3986\n",
              "3           11   2054\n",
              "4           11   4370\n",
              "...        ...    ...\n",
              "313595  138493   4370\n",
              "313596  138493    589\n",
              "313597  138493   2011\n",
              "313598  138493  33615\n",
              "313599  138493    593\n",
              "\n",
              "[313600 rows x 2 columns]"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('json_id/id2show.json', 'r') as json_file:\n",
        "    id2show = json.load(json_file)\n",
        "id2show = json.loads(id2show)\n",
        "\n",
        "with open('json_id/id2profile.json', 'r') as json_file:\n",
        "    id2profile = json.load(json_file)\n",
        "id2profile = json.loads(id2profile)\n",
        "\n",
        "with open('json_id/id2show_2.json', 'r') as json_file:\n",
        "    id2show_2 = json.load(json_file)\n",
        "id2show_2 = json.loads(id2show_2)\n",
        "\n",
        "with open('json_id/id2profile_2.json', 'r') as json_file:\n",
        "    id2profile_2 = json.load(json_file)\n",
        "id2profile_2 = json.loads(id2profile_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id2show.values() == id2show_2.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataloader import DataLoader\n",
        "\n",
        "loader = DataLoader('../../data/train')\n",
        "\n",
        "a,b,c,d,e,f,g = loader.data_loading()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1100\n"
          ]
        }
      ],
      "source": [
        "from models import EASE\n",
        "\n",
        "model = EASE(31360, 6807)\n",
        "print(model.reg_weight)\n",
        "model.fit(g)\n",
        "temp = model.rank_all(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = model.predict_new(test_data_tr=e, test_data_te=f)\n",
        "result[e.nonzero()] = -np.inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from metrics import NDCG_binary_at_k_batch, Recall_at_k_batch\n",
        "\n",
        "len(Recall_at_k_batch(result, f, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = pd.DataFrame()\n",
        "\n",
        "result['user'] = np.repeat(np.arange(31360),10)\n",
        "result['item'] = temp.reshape(-1)\n",
        "\n",
        "result['user'] = result['user'].apply(lambda x: id2profile[str(x)])\n",
        "result['item'] = result['item'].apply(lambda x: id2show[str(x)])\n",
        "\n",
        "result = result.sort_values('user')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = pd.read_csv('submission/EASE_240214_065919.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "result['new'] = temp.reshape(-1)\n",
        "result['new'] = result['new'].apply(lambda x: id2show[str(x)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "result['new_2'] = temp.reshape(-1)\n",
        "result['new_2'] = result['new_2'].apply(lambda x: id2show_2[str(x)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>new</th>\n",
              "      <th>new_2</th>\n",
              "      <th>temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>34048</td>\n",
              "      <td>1193</td>\n",
              "      <td>1193</td>\n",
              "      <td>604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>2571</td>\n",
              "      <td>1208</td>\n",
              "      <td>1208</td>\n",
              "      <td>844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>260</td>\n",
              "      <td>3949</td>\n",
              "      <td>3949</td>\n",
              "      <td>599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>5349</td>\n",
              "      <td>260</td>\n",
              "      <td>260</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>780</td>\n",
              "      <td>750</td>\n",
              "      <td>750</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313595</th>\n",
              "      <td>138493</td>\n",
              "      <td>4973</td>\n",
              "      <td>2081</td>\n",
              "      <td>2081</td>\n",
              "      <td>1151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313596</th>\n",
              "      <td>138493</td>\n",
              "      <td>4306</td>\n",
              "      <td>6942</td>\n",
              "      <td>6942</td>\n",
              "      <td>564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313597</th>\n",
              "      <td>138493</td>\n",
              "      <td>3081</td>\n",
              "      <td>1270</td>\n",
              "      <td>1270</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313598</th>\n",
              "      <td>138493</td>\n",
              "      <td>356</td>\n",
              "      <td>899</td>\n",
              "      <td>899</td>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313599</th>\n",
              "      <td>138493</td>\n",
              "      <td>364</td>\n",
              "      <td>5218</td>\n",
              "      <td>5218</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>313600 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user   item   new  new_2  temp\n",
              "0           11  34048  1193   1193   604\n",
              "1           11   2571  1208   1208   844\n",
              "2           11    260  3949   3949   599\n",
              "3           11   5349   260    260    84\n",
              "4           11    780   750    750   858\n",
              "...        ...    ...   ...    ...   ...\n",
              "313595  138493   4973  2081   2081  1151\n",
              "313596  138493   4306  6942   6942   564\n",
              "313597  138493   3081  1270   1270    72\n",
              "313598  138493    356   899    899   474\n",
              "313599  138493    364  5218   5218   435\n",
              "\n",
              "[313600 rows x 5 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['temp'] = temp.reshape(-1)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = pd.read_csv('../../data/train/train_ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    4643\n",
              "1     170\n",
              "2     531\n",
              "3     616\n",
              "4    2140\n",
              "5    2722\n",
              "6    2313\n",
              "7    2688\n",
              "8    2428\n",
              "9    3113\n",
              "Name: item, dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.item[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "118256    34048\n",
              "118257     2571\n",
              "118258      260\n",
              "118259     5349\n",
              "118250      780\n",
              "118251      480\n",
              "118252     1270\n",
              "118253     1214\n",
              "118254     8644\n",
              "118255        1\n",
              "Name: item, dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.item[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 559,  689,  375, 1486, 1049,  707, 1451,   46,  573,  575]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.full_rank(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('json_id/id2show.json', 'r') as json_file:\n",
        "    id2show = json.load(json_file)\n",
        "id2show = json.loads(id2show)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('json_id/id2profile.json', 'r') as json_file:\n",
        "        id2profile = json.load(json_file)\n",
        "id2profile = json.loads(id2profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../../data/train/train_ratings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp1 = df.groupby('item').user.count()\n",
        "temp2 = df.groupby('user').item.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(np.log10(temp1), bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49.40244910553017"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.exp(3.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     6807.000000\n",
              "mean       757.230939\n",
              "std       1682.973090\n",
              "min         27.000000\n",
              "25%         90.000000\n",
              "50%        197.000000\n",
              "75%        610.500000\n",
              "max      19699.000000\n",
              "Name: user, dtype: float64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(temp2, bins=100, label='all')\n",
        "plt.hist(temp2[temp2<40], bins=1, label='minor')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>sid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11825</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11825</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11825</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5154466</th>\n",
              "      <td>10783</td>\n",
              "      <td>423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5154467</th>\n",
              "      <td>10783</td>\n",
              "      <td>1418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5154468</th>\n",
              "      <td>10783</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5154469</th>\n",
              "      <td>10783</td>\n",
              "      <td>733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5154470</th>\n",
              "      <td>10783</td>\n",
              "      <td>2197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5154471 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           uid   sid\n",
              "0        11825     0\n",
              "1        11825     1\n",
              "2        11825     2\n",
              "3        11825     3\n",
              "4        11825     4\n",
              "...        ...   ...\n",
              "5154466  10783   423\n",
              "5154467  10783  1418\n",
              "5154468  10783   331\n",
              "5154469  10783   733\n",
              "5154470  10783  2197\n",
              "\n",
              "[5154471 rows x 2 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_inf = pd.read_csv('../../data/train/pro_sg/inference.csv')\n",
        "\n",
        "data_inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "t8 = pd.read_csv('../../data/train/pro_sg/train.csv')\n",
        "t9 = pd.read_csv('../../data/train/pro_sg2/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "495925"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t9.shape[0]- t8.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id2show == id2show_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id2profile == id2profile_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0': 27968,\n",
              " '1': 67764,\n",
              " '2': 2581,\n",
              " '3': 82969,\n",
              " '4': 137831,\n",
              " '5': 48639,\n",
              " '6': 97870,\n",
              " '7': 40424,\n",
              " '8': 46835,\n",
              " '9': 79570,\n",
              " '10': 94515,\n",
              " '11': 137854,\n",
              " '12': 11263,\n",
              " '13': 47054,\n",
              " '14': 37161,\n",
              " '15': 90747,\n",
              " '16': 127601,\n",
              " '17': 39688,\n",
              " '18': 3293,\n",
              " '19': 18760,\n",
              " '20': 35856,\n",
              " '21': 102653,\n",
              " '22': 44617,\n",
              " '23': 82532,\n",
              " '24': 81551,\n",
              " '25': 63175,\n",
              " '26': 102732,\n",
              " '27': 123672,\n",
              " '28': 97474,\n",
              " '29': 98293,\n",
              " '30': 85632,\n",
              " '31': 129576,\n",
              " '32': 457,\n",
              " '33': 133514,\n",
              " '34': 30737,\n",
              " '35': 100288,\n",
              " '36': 63791,\n",
              " '37': 78521,\n",
              " '38': 84886,\n",
              " '39': 110828,\n",
              " '40': 131016,\n",
              " '41': 5393,\n",
              " '42': 74051,\n",
              " '43': 15628,\n",
              " '44': 22246,\n",
              " '45': 4055,\n",
              " '46': 37939,\n",
              " '47': 24856,\n",
              " '48': 123019,\n",
              " '49': 68906,\n",
              " '50': 52155,\n",
              " '51': 115183,\n",
              " '52': 28748,\n",
              " '53': 81158,\n",
              " '54': 114566,\n",
              " '55': 43796,\n",
              " '56': 87294,\n",
              " '57': 70546,\n",
              " '58': 105479,\n",
              " '59': 128762,\n",
              " '60': 2161,\n",
              " '61': 38516,\n",
              " '62': 108458,\n",
              " '63': 27281,\n",
              " '64': 46054,\n",
              " '65': 132914,\n",
              " '66': 115134,\n",
              " '67': 24853,\n",
              " '68': 52391,\n",
              " '69': 81884,\n",
              " '70': 97183,\n",
              " '71': 77237,\n",
              " '72': 108574,\n",
              " '73': 85020,\n",
              " '74': 132299,\n",
              " '75': 22220,\n",
              " '76': 25055,\n",
              " '77': 7648,\n",
              " '78': 4149,\n",
              " '79': 6401,\n",
              " '80': 52726,\n",
              " '81': 81131,\n",
              " '82': 137166,\n",
              " '83': 132073,\n",
              " '84': 45939,\n",
              " '85': 1478,\n",
              " '86': 89025,\n",
              " '87': 38760,\n",
              " '88': 20180,\n",
              " '89': 36486,\n",
              " '90': 41870,\n",
              " '91': 84481,\n",
              " '92': 115824,\n",
              " '93': 127535,\n",
              " '94': 85609,\n",
              " '95': 3845,\n",
              " '96': 89834,\n",
              " '97': 46930,\n",
              " '98': 123242,\n",
              " '99': 110754,\n",
              " '100': 39190,\n",
              " '101': 121465,\n",
              " '102': 111522,\n",
              " '103': 131293,\n",
              " '104': 133418,\n",
              " '105': 104084,\n",
              " '106': 4871,\n",
              " '107': 131837,\n",
              " '108': 26460,\n",
              " '109': 74427,\n",
              " '110': 12151,\n",
              " '111': 32162,\n",
              " '112': 120215,\n",
              " '113': 134671,\n",
              " '114': 95282,\n",
              " '115': 92178,\n",
              " '116': 88042,\n",
              " '117': 84016,\n",
              " '118': 134067,\n",
              " '119': 84297,\n",
              " '120': 86941,\n",
              " '121': 71824,\n",
              " '122': 85635,\n",
              " '123': 29235,\n",
              " '124': 38873,\n",
              " '125': 92934,\n",
              " '126': 92273,\n",
              " '127': 52164,\n",
              " '128': 138134,\n",
              " '129': 47120,\n",
              " '130': 39451,\n",
              " '131': 77626,\n",
              " '132': 2668,\n",
              " '133': 24846,\n",
              " '134': 110778,\n",
              " '135': 12384,\n",
              " '136': 65670,\n",
              " '137': 126236,\n",
              " '138': 74126,\n",
              " '139': 117083,\n",
              " '140': 47853,\n",
              " '141': 74676,\n",
              " '142': 11621,\n",
              " '143': 41642,\n",
              " '144': 95600,\n",
              " '145': 51867,\n",
              " '146': 89166,\n",
              " '147': 85469,\n",
              " '148': 38159,\n",
              " '149': 21794,\n",
              " '150': 1732,\n",
              " '151': 128983,\n",
              " '152': 102954,\n",
              " '153': 99270,\n",
              " '154': 67852,\n",
              " '155': 123418,\n",
              " '156': 39222,\n",
              " '157': 18075,\n",
              " '158': 27470,\n",
              " '159': 44576,\n",
              " '160': 92309,\n",
              " '161': 115982,\n",
              " '162': 32341,\n",
              " '163': 42362,\n",
              " '164': 85598,\n",
              " '165': 82763,\n",
              " '166': 86110,\n",
              " '167': 12479,\n",
              " '168': 18316,\n",
              " '169': 42515,\n",
              " '170': 43362,\n",
              " '171': 54860,\n",
              " '172': 8214,\n",
              " '173': 3697,\n",
              " '174': 17726,\n",
              " '175': 77328,\n",
              " '176': 427,\n",
              " '177': 86847,\n",
              " '178': 32659,\n",
              " '179': 131551,\n",
              " '180': 10680,\n",
              " '181': 5406,\n",
              " '182': 108685,\n",
              " '183': 99877,\n",
              " '184': 132026,\n",
              " '185': 138426,\n",
              " '186': 136576,\n",
              " '187': 53422,\n",
              " '188': 55118,\n",
              " '189': 57906,\n",
              " '190': 50751,\n",
              " '191': 21064,\n",
              " '192': 73944,\n",
              " '193': 87440,\n",
              " '194': 59293,\n",
              " '195': 26034,\n",
              " '196': 131862,\n",
              " '197': 38135,\n",
              " '198': 67785,\n",
              " '199': 122301,\n",
              " '200': 121535,\n",
              " '201': 8612,\n",
              " '202': 74286,\n",
              " '203': 67053,\n",
              " '204': 31673,\n",
              " '205': 123863,\n",
              " '206': 100242,\n",
              " '207': 2352,\n",
              " '208': 102878,\n",
              " '209': 117022,\n",
              " '210': 22538,\n",
              " '211': 4822,\n",
              " '212': 113285,\n",
              " '213': 70509,\n",
              " '214': 649,\n",
              " '215': 79264,\n",
              " '216': 81630,\n",
              " '217': 33065,\n",
              " '218': 55521,\n",
              " '219': 57390,\n",
              " '220': 76958,\n",
              " '221': 10387,\n",
              " '222': 133012,\n",
              " '223': 122117,\n",
              " '224': 49479,\n",
              " '225': 13805,\n",
              " '226': 12566,\n",
              " '227': 89618,\n",
              " '228': 97390,\n",
              " '229': 57866,\n",
              " '230': 83676,\n",
              " '231': 22202,\n",
              " '232': 95683,\n",
              " '233': 93239,\n",
              " '234': 101371,\n",
              " '235': 130745,\n",
              " '236': 112852,\n",
              " '237': 130923,\n",
              " '238': 8996,\n",
              " '239': 23599,\n",
              " '240': 29455,\n",
              " '241': 21177,\n",
              " '242': 3075,\n",
              " '243': 128747,\n",
              " '244': 50501,\n",
              " '245': 12242,\n",
              " '246': 108041,\n",
              " '247': 114895,\n",
              " '248': 33646,\n",
              " '249': 4165,\n",
              " '250': 121125,\n",
              " '251': 36835,\n",
              " '252': 95389,\n",
              " '253': 60124,\n",
              " '254': 114889,\n",
              " '255': 58426,\n",
              " '256': 6375,\n",
              " '257': 134037,\n",
              " '258': 94818,\n",
              " '259': 68526,\n",
              " '260': 87755,\n",
              " '261': 112348,\n",
              " '262': 24973,\n",
              " '263': 7328,\n",
              " '264': 44550,\n",
              " '265': 109429,\n",
              " '266': 20615,\n",
              " '267': 17929,\n",
              " '268': 75458,\n",
              " '269': 112365,\n",
              " '270': 125696,\n",
              " '271': 125978,\n",
              " '272': 56076,\n",
              " '273': 126746,\n",
              " '274': 120758,\n",
              " '275': 33540,\n",
              " '276': 14809,\n",
              " '277': 52134,\n",
              " '278': 98560,\n",
              " '279': 105658,\n",
              " '280': 128784,\n",
              " '281': 15469,\n",
              " '282': 94605,\n",
              " '283': 128720,\n",
              " '284': 135795,\n",
              " '285': 53853,\n",
              " '286': 45224,\n",
              " '287': 76659,\n",
              " '288': 101611,\n",
              " '289': 31371,\n",
              " '290': 58086,\n",
              " '291': 19808,\n",
              " '292': 59463,\n",
              " '293': 60535,\n",
              " '294': 18250,\n",
              " '295': 118947,\n",
              " '296': 134290,\n",
              " '297': 130895,\n",
              " '298': 74759,\n",
              " '299': 44870,\n",
              " '300': 56154,\n",
              " '301': 61213,\n",
              " '302': 103306,\n",
              " '303': 126519,\n",
              " '304': 132852,\n",
              " '305': 134197,\n",
              " '306': 25444,\n",
              " '307': 13703,\n",
              " '308': 126294,\n",
              " '309': 18185,\n",
              " '310': 132478,\n",
              " '311': 106394,\n",
              " '312': 83337,\n",
              " '313': 2759,\n",
              " '314': 45937,\n",
              " '315': 115617,\n",
              " '316': 130949,\n",
              " '317': 136283,\n",
              " '318': 81513,\n",
              " '319': 25152,\n",
              " '320': 36561,\n",
              " '321': 24717,\n",
              " '322': 19650,\n",
              " '323': 80207,\n",
              " '324': 71799,\n",
              " '325': 22547,\n",
              " '326': 78890,\n",
              " '327': 7938,\n",
              " '328': 28690,\n",
              " '329': 33808,\n",
              " '330': 90316,\n",
              " '331': 60073,\n",
              " '332': 33433,\n",
              " '333': 63988,\n",
              " '334': 109427,\n",
              " '335': 64367,\n",
              " '336': 103881,\n",
              " '337': 102388,\n",
              " '338': 80771,\n",
              " '339': 38204,\n",
              " '340': 56422,\n",
              " '341': 129762,\n",
              " '342': 32386,\n",
              " '343': 12380,\n",
              " '344': 17022,\n",
              " '345': 68244,\n",
              " '346': 20903,\n",
              " '347': 78597,\n",
              " '348': 120203,\n",
              " '349': 111505,\n",
              " '350': 86129,\n",
              " '351': 63347,\n",
              " '352': 91238,\n",
              " '353': 82603,\n",
              " '354': 58368,\n",
              " '355': 53478,\n",
              " '356': 37339,\n",
              " '357': 132647,\n",
              " '358': 25565,\n",
              " '359': 89310,\n",
              " '360': 9519,\n",
              " '361': 127172,\n",
              " '362': 80838,\n",
              " '363': 17078,\n",
              " '364': 136428,\n",
              " '365': 103719,\n",
              " '366': 109795,\n",
              " '367': 59756,\n",
              " '368': 55328,\n",
              " '369': 7631,\n",
              " '370': 30162,\n",
              " '371': 36154,\n",
              " '372': 105410,\n",
              " '373': 8136,\n",
              " '374': 23079,\n",
              " '375': 90528,\n",
              " '376': 93037,\n",
              " '377': 4329,\n",
              " '378': 110906,\n",
              " '379': 21770,\n",
              " '380': 133426,\n",
              " '381': 31551,\n",
              " '382': 131478,\n",
              " '383': 56976,\n",
              " '384': 89270,\n",
              " '385': 30948,\n",
              " '386': 50297,\n",
              " '387': 86840,\n",
              " '388': 22610,\n",
              " '389': 72802,\n",
              " '390': 73098,\n",
              " '391': 96294,\n",
              " '392': 122170,\n",
              " '393': 27688,\n",
              " '394': 25956,\n",
              " '395': 132120,\n",
              " '396': 84962,\n",
              " '397': 111714,\n",
              " '398': 63434,\n",
              " '399': 85591,\n",
              " '400': 23158,\n",
              " '401': 136119,\n",
              " '402': 80494,\n",
              " '403': 82253,\n",
              " '404': 95081,\n",
              " '405': 97559,\n",
              " '406': 132039,\n",
              " '407': 6039,\n",
              " '408': 106545,\n",
              " '409': 65330,\n",
              " '410': 129254,\n",
              " '411': 23841,\n",
              " '412': 84272,\n",
              " '413': 10164,\n",
              " '414': 131708,\n",
              " '415': 89684,\n",
              " '416': 17428,\n",
              " '417': 22085,\n",
              " '418': 40721,\n",
              " '419': 111524,\n",
              " '420': 86784,\n",
              " '421': 79531,\n",
              " '422': 115305,\n",
              " '423': 7453,\n",
              " '424': 61451,\n",
              " '425': 104129,\n",
              " '426': 93547,\n",
              " '427': 4173,\n",
              " '428': 56782,\n",
              " '429': 21167,\n",
              " '430': 88226,\n",
              " '431': 13345,\n",
              " '432': 100087,\n",
              " '433': 9736,\n",
              " '434': 15816,\n",
              " '435': 134983,\n",
              " '436': 6258,\n",
              " '437': 138135,\n",
              " '438': 78472,\n",
              " '439': 3588,\n",
              " '440': 131615,\n",
              " '441': 106865,\n",
              " '442': 34011,\n",
              " '443': 21132,\n",
              " '444': 124329,\n",
              " '445': 83200,\n",
              " '446': 56969,\n",
              " '447': 42491,\n",
              " '448': 54429,\n",
              " '449': 26214,\n",
              " '450': 127313,\n",
              " '451': 78567,\n",
              " '452': 55954,\n",
              " '453': 33155,\n",
              " '454': 109648,\n",
              " '455': 89372,\n",
              " '456': 25409,\n",
              " '457': 4696,\n",
              " '458': 7798,\n",
              " '459': 21408,\n",
              " '460': 66159,\n",
              " '461': 125507,\n",
              " '462': 110069,\n",
              " '463': 108717,\n",
              " '464': 127731,\n",
              " '465': 40755,\n",
              " '466': 130126,\n",
              " '467': 26794,\n",
              " '468': 85420,\n",
              " '469': 56758,\n",
              " '470': 84101,\n",
              " '471': 87748,\n",
              " '472': 94464,\n",
              " '473': 57814,\n",
              " '474': 135579,\n",
              " '475': 99747,\n",
              " '476': 14166,\n",
              " '477': 56817,\n",
              " '478': 34562,\n",
              " '479': 105889,\n",
              " '480': 6594,\n",
              " '481': 29081,\n",
              " '482': 118926,\n",
              " '483': 119839,\n",
              " '484': 69234,\n",
              " '485': 105173,\n",
              " '486': 72357,\n",
              " '487': 65061,\n",
              " '488': 90810,\n",
              " '489': 95645,\n",
              " '490': 66030,\n",
              " '491': 22336,\n",
              " '492': 123040,\n",
              " '493': 44496,\n",
              " '494': 110025,\n",
              " '495': 53233,\n",
              " '496': 136816,\n",
              " '497': 51245,\n",
              " '498': 52074,\n",
              " '499': 7007,\n",
              " '500': 92572,\n",
              " '501': 118542,\n",
              " '502': 3957,\n",
              " '503': 48759,\n",
              " '504': 14972,\n",
              " '505': 92777,\n",
              " '506': 43972,\n",
              " '507': 87822,\n",
              " '508': 10721,\n",
              " '509': 68254,\n",
              " '510': 70924,\n",
              " '511': 22825,\n",
              " '512': 35630,\n",
              " '513': 266,\n",
              " '514': 131213,\n",
              " '515': 22168,\n",
              " '516': 66713,\n",
              " '517': 137818,\n",
              " '518': 19842,\n",
              " '519': 73835,\n",
              " '520': 46998,\n",
              " '521': 120735,\n",
              " '522': 82472,\n",
              " '523': 22965,\n",
              " '524': 16743,\n",
              " '525': 114922,\n",
              " '526': 61561,\n",
              " '527': 13575,\n",
              " '528': 2308,\n",
              " '529': 106507,\n",
              " '530': 29729,\n",
              " '531': 70342,\n",
              " '532': 131580,\n",
              " '533': 117722,\n",
              " '534': 26004,\n",
              " '535': 125256,\n",
              " '536': 54218,\n",
              " '537': 39778,\n",
              " '538': 45100,\n",
              " '539': 29287,\n",
              " '540': 99643,\n",
              " '541': 8944,\n",
              " '542': 91769,\n",
              " '543': 6268,\n",
              " '544': 86299,\n",
              " '545': 98590,\n",
              " '546': 130767,\n",
              " '547': 67373,\n",
              " '548': 3905,\n",
              " '549': 65680,\n",
              " '550': 40234,\n",
              " '551': 15139,\n",
              " '552': 6795,\n",
              " '553': 55390,\n",
              " '554': 25284,\n",
              " '555': 66594,\n",
              " '556': 115686,\n",
              " '557': 31436,\n",
              " '558': 134100,\n",
              " '559': 5770,\n",
              " '560': 124758,\n",
              " '561': 107150,\n",
              " '562': 5544,\n",
              " '563': 17877,\n",
              " '564': 34727,\n",
              " '565': 105214,\n",
              " '566': 60226,\n",
              " '567': 32284,\n",
              " '568': 135126,\n",
              " '569': 540,\n",
              " '570': 33387,\n",
              " '571': 119046,\n",
              " '572': 4802,\n",
              " '573': 93670,\n",
              " '574': 100273,\n",
              " '575': 133269,\n",
              " '576': 85832,\n",
              " '577': 2742,\n",
              " '578': 361,\n",
              " '579': 83640,\n",
              " '580': 131351,\n",
              " '581': 12530,\n",
              " '582': 79434,\n",
              " '583': 20375,\n",
              " '584': 119896,\n",
              " '585': 121107,\n",
              " '586': 41590,\n",
              " '587': 84487,\n",
              " '588': 98073,\n",
              " '589': 46254,\n",
              " '590': 82990,\n",
              " '591': 73387,\n",
              " '592': 10829,\n",
              " '593': 64882,\n",
              " '594': 133729,\n",
              " '595': 5148,\n",
              " '596': 138048,\n",
              " '597': 86977,\n",
              " '598': 115369,\n",
              " '599': 5692,\n",
              " '600': 42670,\n",
              " '601': 27130,\n",
              " '602': 44963,\n",
              " '603': 73948,\n",
              " '604': 70380,\n",
              " '605': 38547,\n",
              " '606': 115586,\n",
              " '607': 18743,\n",
              " '608': 40555,\n",
              " '609': 11074,\n",
              " '610': 49820,\n",
              " '611': 84849,\n",
              " '612': 96891,\n",
              " '613': 60069,\n",
              " '614': 51596,\n",
              " '615': 111772,\n",
              " '616': 60418,\n",
              " '617': 113030,\n",
              " '618': 110085,\n",
              " '619': 98877,\n",
              " '620': 84125,\n",
              " '621': 66576,\n",
              " '622': 50740,\n",
              " '623': 118473,\n",
              " '624': 8963,\n",
              " '625': 114232,\n",
              " '626': 67525,\n",
              " '627': 14091,\n",
              " '628': 775,\n",
              " '629': 73498,\n",
              " '630': 136782,\n",
              " '631': 74468,\n",
              " '632': 111726,\n",
              " '633': 83849,\n",
              " '634': 47870,\n",
              " '635': 14133,\n",
              " '636': 78289,\n",
              " '637': 94364,\n",
              " '638': 45555,\n",
              " '639': 131579,\n",
              " '640': 67869,\n",
              " '641': 32473,\n",
              " '642': 3397,\n",
              " '643': 16154,\n",
              " '644': 2089,\n",
              " '645': 20084,\n",
              " '646': 90163,\n",
              " '647': 63977,\n",
              " '648': 71193,\n",
              " '649': 56115,\n",
              " '650': 27885,\n",
              " '651': 91589,\n",
              " '652': 94234,\n",
              " '653': 22013,\n",
              " '654': 73849,\n",
              " '655': 129362,\n",
              " '656': 23636,\n",
              " '657': 23694,\n",
              " '658': 105083,\n",
              " '659': 111420,\n",
              " '660': 33700,\n",
              " '661': 44137,\n",
              " '662': 22249,\n",
              " '663': 6713,\n",
              " '664': 133387,\n",
              " '665': 7322,\n",
              " '666': 59777,\n",
              " '667': 119925,\n",
              " '668': 116590,\n",
              " '669': 101853,\n",
              " '670': 39114,\n",
              " '671': 129803,\n",
              " '672': 25322,\n",
              " '673': 21350,\n",
              " '674': 110948,\n",
              " '675': 108240,\n",
              " '676': 105756,\n",
              " '677': 79414,\n",
              " '678': 15532,\n",
              " '679': 2008,\n",
              " '680': 121823,\n",
              " '681': 89849,\n",
              " '682': 63630,\n",
              " '683': 45298,\n",
              " '684': 38845,\n",
              " '685': 116483,\n",
              " '686': 105676,\n",
              " '687': 16280,\n",
              " '688': 41120,\n",
              " '689': 6743,\n",
              " '690': 23978,\n",
              " '691': 39212,\n",
              " '692': 31900,\n",
              " '693': 73361,\n",
              " '694': 107060,\n",
              " '695': 115481,\n",
              " '696': 5364,\n",
              " '697': 57515,\n",
              " '698': 62264,\n",
              " '699': 63132,\n",
              " '700': 61445,\n",
              " '701': 135105,\n",
              " '702': 72393,\n",
              " '703': 24118,\n",
              " '704': 79899,\n",
              " '705': 97904,\n",
              " '706': 53113,\n",
              " '707': 115198,\n",
              " '708': 19903,\n",
              " '709': 122444,\n",
              " '710': 119969,\n",
              " '711': 125322,\n",
              " '712': 26469,\n",
              " '713': 120829,\n",
              " '714': 12718,\n",
              " '715': 83136,\n",
              " '716': 75573,\n",
              " '717': 45550,\n",
              " '718': 1551,\n",
              " '719': 124180,\n",
              " '720': 14072,\n",
              " '721': 50910,\n",
              " '722': 36510,\n",
              " '723': 132618,\n",
              " '724': 67387,\n",
              " '725': 57792,\n",
              " '726': 88403,\n",
              " '727': 116489,\n",
              " '728': 36564,\n",
              " '729': 64067,\n",
              " '730': 8140,\n",
              " '731': 112161,\n",
              " '732': 63755,\n",
              " '733': 74446,\n",
              " '734': 31047,\n",
              " '735': 98610,\n",
              " '736': 131846,\n",
              " '737': 115572,\n",
              " '738': 62013,\n",
              " '739': 53848,\n",
              " '740': 79010,\n",
              " '741': 100007,\n",
              " '742': 29862,\n",
              " '743': 57237,\n",
              " '744': 104951,\n",
              " '745': 43242,\n",
              " '746': 32181,\n",
              " '747': 132417,\n",
              " '748': 30817,\n",
              " '749': 123525,\n",
              " '750': 30650,\n",
              " '751': 11863,\n",
              " '752': 12438,\n",
              " '753': 65027,\n",
              " '754': 130984,\n",
              " '755': 84090,\n",
              " '756': 25120,\n",
              " '757': 110894,\n",
              " '758': 70056,\n",
              " '759': 97355,\n",
              " '760': 109299,\n",
              " '761': 10822,\n",
              " '762': 100608,\n",
              " '763': 22071,\n",
              " '764': 60068,\n",
              " '765': 72983,\n",
              " '766': 42390,\n",
              " '767': 118216,\n",
              " '768': 96010,\n",
              " '769': 2561,\n",
              " '770': 90014,\n",
              " '771': 37357,\n",
              " '772': 37360,\n",
              " '773': 6995,\n",
              " '774': 113209,\n",
              " '775': 26241,\n",
              " '776': 73992,\n",
              " '777': 14561,\n",
              " '778': 29931,\n",
              " '779': 89946,\n",
              " '780': 57323,\n",
              " '781': 104468,\n",
              " '782': 91073,\n",
              " '783': 37762,\n",
              " '784': 60371,\n",
              " '785': 123549,\n",
              " '786': 83628,\n",
              " '787': 56484,\n",
              " '788': 37047,\n",
              " '789': 127486,\n",
              " '790': 72441,\n",
              " '791': 14796,\n",
              " '792': 85149,\n",
              " '793': 98604,\n",
              " '794': 39458,\n",
              " '795': 33661,\n",
              " '796': 117874,\n",
              " '797': 30686,\n",
              " '798': 52993,\n",
              " '799': 64477,\n",
              " '800': 91799,\n",
              " '801': 125056,\n",
              " '802': 82769,\n",
              " '803': 118477,\n",
              " '804': 83122,\n",
              " '805': 135288,\n",
              " '806': 33408,\n",
              " '807': 49147,\n",
              " '808': 103493,\n",
              " '809': 2210,\n",
              " '810': 27213,\n",
              " '811': 51232,\n",
              " '812': 49772,\n",
              " '813': 13254,\n",
              " '814': 39041,\n",
              " '815': 137054,\n",
              " '816': 121672,\n",
              " '817': 15059,\n",
              " '818': 73697,\n",
              " '819': 55410,\n",
              " '820': 129563,\n",
              " '821': 22886,\n",
              " '822': 49662,\n",
              " '823': 53030,\n",
              " '824': 45281,\n",
              " '825': 770,\n",
              " '826': 24036,\n",
              " '827': 132377,\n",
              " '828': 121100,\n",
              " '829': 38246,\n",
              " '830': 53735,\n",
              " '831': 77639,\n",
              " '832': 27082,\n",
              " '833': 114244,\n",
              " '834': 65530,\n",
              " '835': 82148,\n",
              " '836': 20369,\n",
              " '837': 40773,\n",
              " '838': 5839,\n",
              " '839': 39436,\n",
              " '840': 96887,\n",
              " '841': 5342,\n",
              " '842': 132600,\n",
              " '843': 45026,\n",
              " '844': 8008,\n",
              " '845': 20563,\n",
              " '846': 133187,\n",
              " '847': 77873,\n",
              " '848': 128695,\n",
              " '849': 126569,\n",
              " '850': 26808,\n",
              " '851': 82105,\n",
              " '852': 129321,\n",
              " '853': 10907,\n",
              " '854': 120330,\n",
              " '855': 113181,\n",
              " '856': 40763,\n",
              " '857': 125622,\n",
              " '858': 103917,\n",
              " '859': 116823,\n",
              " '860': 45613,\n",
              " '861': 64464,\n",
              " '862': 28465,\n",
              " '863': 95529,\n",
              " '864': 132484,\n",
              " '865': 96161,\n",
              " '866': 17609,\n",
              " '867': 8625,\n",
              " '868': 108028,\n",
              " '869': 88672,\n",
              " '870': 116484,\n",
              " '871': 56296,\n",
              " '872': 67051,\n",
              " '873': 65241,\n",
              " '874': 72715,\n",
              " '875': 110512,\n",
              " '876': 50211,\n",
              " '877': 47800,\n",
              " '878': 45408,\n",
              " '879': 60669,\n",
              " '880': 13426,\n",
              " '881': 90175,\n",
              " '882': 76057,\n",
              " '883': 22056,\n",
              " '884': 33086,\n",
              " '885': 61054,\n",
              " '886': 27529,\n",
              " '887': 55563,\n",
              " '888': 46367,\n",
              " '889': 8659,\n",
              " '890': 110488,\n",
              " '891': 89247,\n",
              " '892': 96985,\n",
              " '893': 74430,\n",
              " '894': 137811,\n",
              " '895': 59926,\n",
              " '896': 22882,\n",
              " '897': 74322,\n",
              " '898': 108786,\n",
              " '899': 107921,\n",
              " '900': 6721,\n",
              " '901': 91169,\n",
              " '902': 79091,\n",
              " '903': 2004,\n",
              " '904': 100386,\n",
              " '905': 51021,\n",
              " '906': 1065,\n",
              " '907': 124584,\n",
              " '908': 78984,\n",
              " '909': 97284,\n",
              " '910': 101754,\n",
              " '911': 129448,\n",
              " '912': 118255,\n",
              " '913': 137025,\n",
              " '914': 92814,\n",
              " '915': 67596,\n",
              " '916': 38992,\n",
              " '917': 133186,\n",
              " '918': 90724,\n",
              " '919': 55008,\n",
              " '920': 98336,\n",
              " '921': 52401,\n",
              " '922': 48885,\n",
              " '923': 40436,\n",
              " '924': 30967,\n",
              " '925': 133812,\n",
              " '926': 81894,\n",
              " '927': 23702,\n",
              " '928': 129033,\n",
              " '929': 56290,\n",
              " '930': 19310,\n",
              " '931': 2925,\n",
              " '932': 93619,\n",
              " '933': 119478,\n",
              " '934': 125641,\n",
              " '935': 93897,\n",
              " '936': 61193,\n",
              " '937': 24595,\n",
              " '938': 59796,\n",
              " '939': 33837,\n",
              " '940': 47556,\n",
              " '941': 106464,\n",
              " '942': 5954,\n",
              " '943': 49535,\n",
              " '944': 43134,\n",
              " '945': 133682,\n",
              " '946': 22399,\n",
              " '947': 118901,\n",
              " '948': 82124,\n",
              " '949': 62848,\n",
              " '950': 93803,\n",
              " '951': 12862,\n",
              " '952': 86060,\n",
              " '953': 118315,\n",
              " '954': 52810,\n",
              " '955': 111857,\n",
              " '956': 39715,\n",
              " '957': 7661,\n",
              " '958': 1486,\n",
              " '959': 34116,\n",
              " '960': 128233,\n",
              " '961': 55491,\n",
              " '962': 7708,\n",
              " '963': 34005,\n",
              " '964': 107688,\n",
              " '965': 85617,\n",
              " '966': 71077,\n",
              " '967': 127759,\n",
              " '968': 25129,\n",
              " '969': 115539,\n",
              " '970': 27887,\n",
              " '971': 123875,\n",
              " '972': 76380,\n",
              " '973': 1770,\n",
              " '974': 68226,\n",
              " '975': 41669,\n",
              " '976': 115416,\n",
              " '977': 72107,\n",
              " '978': 17158,\n",
              " '979': 69493,\n",
              " '980': 8407,\n",
              " '981': 42322,\n",
              " '982': 68605,\n",
              " '983': 66813,\n",
              " '984': 129531,\n",
              " '985': 79829,\n",
              " '986': 122232,\n",
              " '987': 372,\n",
              " '988': 6125,\n",
              " '989': 20117,\n",
              " '990': 19121,\n",
              " '991': 117165,\n",
              " '992': 11182,\n",
              " '993': 105498,\n",
              " '994': 6431,\n",
              " '995': 56175,\n",
              " '996': 35396,\n",
              " '997': 77412,\n",
              " '998': 6333,\n",
              " '999': 97568,\n",
              " ...}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id2profile_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
